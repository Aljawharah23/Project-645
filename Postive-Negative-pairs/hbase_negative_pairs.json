[
    [
        "HBASE-14148",
        "HBASE-8394",
        "Web UI Framable Page The web UIs do not include the \"X-Frame-Options\" header to prevent the pages from being framed from another site.  \r\n\r\nReference:\r\nhttps://www.owasp.org/index.php/Clickjacking\r\nhttps://www.owasp.org/index.php/Clickjacking_Defense_Cheat_Sheet\r\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/X-Frame-Options\r\n",
        "Utilize isFileClosed() so that the wait for lease recovery can be optimized In HDFS-4525, the following API was added:\r\n{code}\r\n  /**\r\n   * Get the close status of a file\r\n   * @param src The path to the file\r\n   *\r\n   * @return return true if file is closed\r\n   * @throws FileNotFoundException if the file does not exist.\r\n   * @throws IOException If an I/O error occurred     \r\n   */\r\n  public boolean isFileClosed(Path src) throws IOException {\r\n{code}\r\nIt is not available in hadoop 1.1 at the moment.\r\n\r\nIn HBASE-8389, there was discussion for utilizing isFileClosed() to optimize the wait time for lease recovery.\r\n\r\nSubsequent lease recovery request for the same Path would preempt outstanding recovery. But if we wait for one particular recovery request to complete without limit on duration, we may incur penalty due to various failure scenarios such as the primary Data Node chosen by Namenode being stale, etc.\r\n\r\nThis JIRA continues the work for 0.95 / trunk."
    ],
    [
        "HBASE-14873",
        "HBASE-8487",
        "Problems around BoundedByteBufferPool providing direct buffers HBASE-13819 made BoundedByteBufferPool provide direct buffers.\r\n\r\nSee RpcServer.java:\r\n{code}\r\n...\r\nclass Call implements RpcCallContext {\r\n  protected synchronized void setResponse(...) {\r\n...\r\n    this.cellBlock = ipcUtil.buildCellBlock(..., reservoir);\r\n...\r\n    bc = new BufferChain(..., this.cellBlock);\r\n    if (connection.useWrap) {\r\n      bc = wrapWithSasl(bc);\r\n    }\r\n...\r\n  private BufferChain wrapWithSasl(BufferChain bc) throws IOException {\r\n...\r\n    byte[] responseBytes = bc.getBytes();\r\n...\r\n{code}\r\n\r\n{{cellBlock}} is expected to be a direct buffer retrieved from {{reservoir}} (but not always), and {{bc}} may be composed of both direct and non-direct buffers.\r\n\r\nAnd then, see BufferChain.java:\r\n{code}\r\nbyte [] getBytes() {\r\n...\r\n    for (ByteBuffer bb: this.buffers) {\r\n      System.arraycopy(bb.array(), ...);\r\n{code}\r\n\r\nA direct buffer doesn't give its array, and will throw UnsupportedOperationException.\r\n\r\nAnother problem; {{cellBlock}} is allowed to be a non-direct buffer, and after use it will be put to {{reservoir}}, mixing direct and non-direct buffers in the pool.\r\n\r\n\r\n",
        "Wrong description about regionservers in 2.4. Example configurations Wrong description about regionservers in \"2.4. Example configurations\"."
    ],
    [
        "HBASE-3416",
        "HBASE-9062",
        "For intra-row scanning, the update readers notification resets the query matcher and can lead to incorrect behavior In {{StoreScanner.resetScannerStack()}}, which is called on the first {{next()}} call after readers have been updated, we do a query matcher reset.  Normally this is not an issue because the query matcher does not need to maintain state between rows.  However, if doing intra-row scanning w/ the specified limit, we could have the query matcher reset in the middle of reading a row.  This could lead to incorrect behavior (too many versions coming back, etc).",
        "Remove TestReplicationKillRs* tests temporarily Removing this suite of tests for now.  [~jdcryans] is working on fixing these over in HBASE-8615 but currently he is off in \"exotic location\".  Removing meantime to get in some clean builds.  Will put back in HBASE-9061 which is critical for 0.95.2"
    ],
    [
        "HBASE-9797",
        "HBASE-1440",
        "Multi row transactions are not atomic for scanners Multi row atomic puts, as implemented by the coprocessor API is atomic for gets and multi gets, but not so much for scanners. \r\n\r\nmvcc read point, as of today, is only kept in RS memory. When a client starts the scan, we create a new scanner object and save the mvcc read point of the scan there. Since the scan API is row-based, the scan results are only made visible to clients row-per-row, and the client scanner keep track of the last row seen. \r\n\r\nSo, for a multi-row atomic update, the scanner might get an mvcc number which is less than the commit point of the multi-row update, so it will skip some rows in the scan (will not see the rows). However, in case of RS failover, a new scanner will be created which will have a mvcc read number larger than the multi-row update commit number. So the scanner will see the remaining rows from the transaction. \r\n\r\nExample: \r\n{code}\r\nmulti put : { {row1, c1, v1}, {row100, c1, v100} } mvcc write number = 2\r\nscan : scan from row1 to row100  mvcc read number = 1\r\n{code}\r\n\r\nscanner will not see row1. If RS fails before scanner reaches row100, the new scanner will get mvcc read number > 2, so it will see row100. \r\n\r\n\r\nThere might be a couple of ways to fix this. First approach (as suggested by Sergey) is that we can wrap the Scanner into an atomic scanner implementation, which will restart the scan in case of a socket timeout or server failure, etc. This will batch up the results so that the rows are not visible. For small scans (like meta) this might be viable. \r\n\r\n\r\nThe second way to properly fix this is, first finish up the patch at HBASE-8763, then change the scanner to obtain an mvcc number from the RS in scanner open, and save the mvcc number in the client side. Upon failure, the scanner will continue the scan where it is left. We have to keep the low watermark (the smallest mvcc read number of the scanners currently open) differently. Currently that number is already tracked, but not across RS failover. We can do timeouts to manage the low watermark I think. \r\nThis approach also enables us to implement cell-based streaming scan instead of row-based approach we have today. \r\n\r\nOpened the issue, so that it is tracked. Feel free to pick it up if you like. \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "master won't go down because joined on a rootscanner that is waiting for ever The below wait depends on an open event hitting the master.  Won't happen if we're shutting down.\r\n{code}\r\n\"RegionManager.rootScanner\" daemon prio=10 tid=0x00007fdc98197c00 nid=0x7538 in Object.wait() [0x0000000040e7f000..0x0000000040e7fa80]\r\n   java.lang.Thread.State: WAITING (on object monitor)\r\n    at java.lang.Object.wait(Native Method)\r\n    at java.lang.Object.wait(Object.java:485)\r\n    at org.apache.hadoop.hbase.master.RegionManager.waitForRootRegionLocation(RegionManager.java:981)\r\n    - locked <0x00007fdcad0cacd0> (a java.util.concurrent.atomic.AtomicReference)\r\n    at org.apache.hadoop.hbase.master.HMaster.waitForRootRegionLocation(HMaster.java:362)\r\n    at org.apache.hadoop.hbase.master.RootScanner.scanRoot(RootScanner.java:45)\r\n    at org.apache.hadoop.hbase.master.RootScanner.maintenanceScan(RootScanner.java:79)\r\n    at org.apache.hadoop.hbase.master.BaseScanner.chore(BaseScanner.java:135)\r\n    at org.apache.hadoop.hbase.Chore.run(Chore.java:68)\r\n{code}"
    ],
    [
        "HBASE-2374",
        "HBASE-2252",
        "TableInputFormat - Configurable parameter to add column families  Currently , TIF supports hbase.mapreduce.scan.columns to add family:qualifiers as a conf parameter. \r\n\r\nThis adds -  hbase.mapreduce.scan.column.family , as a configurable parameter to add a family to the scan of TIF. \r\n\r\nPatch against trunk , but does not break backward compatibility. \r\n",
        "Mapping a very big table kills region servers Currently TableInputFormat doesn't change the block caching behavior of scans and one of our table grew so big that using the defaults we kill a least one region server per job run (because of GCs even if we have a heap of 7GB). This doesn't scale well, we should set it by default to false."
    ],
    [
        "HBASE-228",
        "HBASE-4148",
        "[hbase] Options not passed to rest/thrift Billy Pearson over in HADOOP-2593 reported:\n\n{code}\nbin/hbase-daemon.sh start rest --bind=127.0.0.1\n2008-01-21 03:11:14,916 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4\n2008-01-21 03:11:14,941 INFO org.mortbay.util.Credential: Checking Resource aliases\n2008-01-21 03:11:16,404 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@153f67e\n2008-01-21 03:11:16,600 INFO org.mortbay.util.Container: Started WebApplicationContext[/api,rest]\n2008-01-21 03:11:16,720 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:60050\n2008-01-21 03:11:16,721 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@192b996\n{code}\n\nThis shows the bind option is not being passed bind on 0.0.0.0 not 127.0.0.1 as it should",
        "HFileOutputFormat doesn't fill in TIMERANGE_KEY metadata When HFiles are flushed through the normal path, they include an attribute TIMERANGE_KEY which can be used to cull HFiles when performing a time-restricted scan. Files produced by HFileOutputFormat are currently missing this metadata."
    ],
    [
        "HBASE-11844",
        "HBASE-12821",
        "region_mover.rb load enters an infinite loop if region already present on target server region_mover.rb load enters an infinite loop if the region it's attempting to move is already present on the target server.\r\n\r\nI'm attaching a log extract from this situation, and the trivial fix.",
        "Describe on table doesn't show table attributes on hbase shell 1) hbase(main):003:0> create 'test','CF'\r\n2) hbase(main):006:0> alter 'test', METADATA => {'TEST_PROPERTY' => 'TEST_VALUE'}\r\n3) hbase(main):007:0> describe 'test'\r\n{NAME => 'CF', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}   \r\n\r\nIssue : The added property , table attribute, isn't getting displayed.\r\n\r\nNote : If we check the table description from master page, we can see the changed property.\r\n'test', {TABLE_ATTRIBUTES => {METADATA => {'TEST_PROPERTY' => 'TEST_VALUE'}}, {NAME => 'CF'}  "
    ],
    [
        "HBASE-4464",
        "HBASE-637",
        "Make region balancing parallel with balancer.balanceCluster() balancer.balanceCluster() generates RegionPlans for HMaster.balance() to execute.\r\nWe don't retract any RegionPlan in balancer.balanceCluster().\r\nIn the near future, more complex algorithm would be introduced to try achieving maximum block location affinity for the regions to be moved. This means balancer.balanceCluster() would take longer to return.\r\n\r\nThis JIRA makes region balancing parallel with balancer.balanceCluster()\r\nMeaning region balancing would be performed when balancer.balanceCluster() is still running.",
        "Update filter test to ue ColumnValueFilter instead of RegExpRowFilter Filtering by column value in RegExpRowFilter has been deprecated in favor of ColumnValueFilter. Filter tests should be modified to use ColumnValueFilter."
    ],
    [
        "HBASE-2663",
        "HBASE-2925",
        "LRU cache makes needless datastructure copies during eviction Was browsing the LRU eviction code and came upon some very inefficient code. When we do eviction, BlockBucket.free() calls queue.get() which first inserts everything from the PriorityQueue<Block> into a LinkedList, then copies that entire linked list into an array. We then iterate over usually just a small percentage of the array to free some blocks until we have freed the requested amount.\r\n\r\nWe ought to be able to just pull items out of the PriorityQueue directly and avoid all the churn.",
        "LRU of HConnectionManager.HBASE_INSTANCES breaks if HBaseConfiguration is changed {{HConnectionManager.getConnection(config)}} caches the created {{TableServer}} in {{HBASE_INSTANCES}} (a {{LinkedHashMap}} ) which is keyed by the configuration instance itself.\r\nGiven the current implementation of {{hashCode()}} (and {{equals()}}) of {{HBaseConfiguration}}, the hash code of the configuration is changed if any of its properties are changed, which will cause the keys of {{HBASE_INSTANCES}} to be inconsistent with the hashtable that contains them, making some entries unreachable.\r\nIn this case, when the map's LRU strategy needs to remove the oldest entry, it tries to remove it based on the oldest key, which no longer gives the original hash code, therefore the lookup in {{HBASE_INSTANCES.remove(oldest)}} doesn't actually remove anything.\r\n\r\nThis has been observed to lead to OOM errors in long running clients.\r\n"
    ],
    [
        "HBASE-14400",
        "HBASE-8330",
        "Fix HBase RPC protection documentation HBase configuration 'hbase.rpc.protection' can be set to 'authentication', 'integrity' or 'privacy'.\r\n\"authentication means authentication only and no integrity or privacy; integrity implies\r\nauthentication and integrity are enabled; and privacy implies all of\r\nauthentication, integrity and privacy are enabled.\"\r\n\r\nHowever hbase ref guide incorrectly suggests in some places to set the value to 'auth-conf' instead of 'privacy'. Setting value to 'auth-conf' doesn't provide rpc encryption which is what user wants.\r\n\r\nThis jira will fix:\r\n- documentation: change 'auth-conf' references to 'privacy'\r\n- SaslUtil to support both set of values (privacy/integrity/authentication and auth-conf/auth-int/auth) to be backward compatible with what was being suggested till now.\r\n- change 'hbase.thrift.security.qop' to be consistent with other similar configurations by using same set of values (privacy/integrity/authentication).",
        "What is the necessity of having a private ThreadLocal in FSReaderV2 I was trying to investigate the scenarios in which we perform a seek back of 24 bytes(Header size) while we do a HFileBlock read. In the process I stumbled upon this issue. In order to avoid the seek back problem, what we do is to store the header of the next block in a class named PrefetchedHeader. This prefetched header is stored as a private ThreadLocal object in the FSReaderV2 class. I was wondering why we would be needing a ThreadLocalc when each FSReader object has its own PrefetchedHeader object and moreover if its private. Can anybody familiar with this part of the code tell me what was the design decision that was taken at that time?"
    ],
    [
        "HBASE-2165",
        "HBASE-14022",
        "Improve fragmentation display and implementation Improve by \r\n\r\n- moving the \"blocking\" FS scan into a thread so that the UI loads fast and initially displays \"n/a\" but once it has completed the scan it displays the proper numbers\r\n- explaining what fragmentation means to the user (better hints or help text in UI)\r\n- Switch -ROOT- (and maybe even .META.?) to simply say \"Yes\" or a tick that it is fragmented as it only has 0% or 100% available (since it has only a single region)\r\n- also computing the space occupied by each table and the total and - if easily done - add a graph to display it (Google Pie Chart would be nice but is an external link)",
        "TestMultiTableSnapshotInputFormatImpl uses a class only available in JRE 1.7+ Only applicable to 0.98. Another instance where minimum supported versions of the JRE/JDK and Hadoop lag far behind current committer dev tooling. Fix."
    ],
    [
        "HBASE-1459",
        "HBASE-14782",
        "CME during memcache flush forces HRS shutdown I just saw this on my 0.19.1 cluster:\r\n\r\n2009-05-30 03:57:19,559 FATAL org.apache.hadoop.hbase.regionserver.MemcacheFlusher: Replay of hlog required. Forcing server shutdown\r\norg.apache.hadoop.hbase.DroppedSnapshotException: region: table,rowkey,1243547152622\r\n    at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:897)\r\n    at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:790)\r\n    at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.flushRegion(MemcacheFlusher.java:228)\r\n    at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.run(MemcacheFlusher.java:138)\r\nCaused by: java.util.ConcurrentModificationException\r\n    at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1100)\r\n    at java.util.TreeMap$EntryIterator.next(TreeMap.java:1136)\r\n    at java.util.TreeMap$EntryIterator.next(TreeMap.java:1131)\r\n    at org.apache.hadoop.hbase.regionserver.HStore.internalFlushCache(HStore.java:678)\r\n    at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:636)\r\n    at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:882)\r\n    ... 3 more",
        "FuzzyRowFilter skips valid rows The issue may affect not only master branch, but previous releases as well.\r\nThis is from one of our customers:\r\n{quote}\r\nWe are experiencing a problem with the FuzzyRowFilter for HBase scan. We think that it is a bug. \r\nFuzzy filter should pick a row if it matches filter criteria irrespective of other rows present in table but filter is dropping a row depending on some other row present in table. \r\n\r\n\r\nDetails/Step to reproduce/Sample outputs below: \r\n\r\nMissing row key: \\x9C\\x00\\x044\\x00\\x00\\x00\\x00 \r\nCausing row key: \\x9C\\x00\\x03\\xE9e\\xBB{X\\x1Fwts\\x1F\\x15vRX \r\n\r\n\r\nPrerequisites \r\n1. Create a test table. HBase shell command -- create 'fuzzytest','d' \r\n2. Insert some test data. HBase shell commands: \r\n\u2022 put 'fuzzytest',\"\\x9C\\x00\\x044\\x00\\x00\\x00\\x00\",'d:a','junk' \r\n\u2022 put 'fuzzytest',\"\\x9C\\x00\\x044\\x01\\x00\\x00\\x00\",'d:a','junk' \r\n\u2022 put 'fuzzytest',\"\\x9C\\x00\\x044\\x00\\x01\\x00\\x00\",'d:a','junk' \r\n\u2022 put 'fuzzytest',\"\\x9C\\x00\\x044\\x00\\x00\\x01\\x00\",'d:a','junk' \r\n\u2022 put 'fuzzytest',\"\\x9C\\x00\\x044\\x00\\x01\\x00\\x01\",'d:a','junk' \r\n\u2022 put 'fuzzytest',\"\\x9B\\x00\\x044e\\xBB\\xB2\\xBB\",'d:a','junk' \r\n\u2022 put 'fuzzytest',\"\\x9D\\x00\\x044e\\xBB\\xB2\\xBB\",'d:a','junk' \r\nNow when you run the code, you will find \\x9C\\x00\\x044\\x00\\x00\\x00\\x00 in output because it matches filter criteria. (Refer how to run code below) \r\nInsert the row key causing bug: \r\nHBase shell command: put 'fuzzytest',\"\\x9C\\x00\\x03\\xE9e\\xBB{X\\x1Fwts\\x1F\\x15vRX\",'d:a','junk' \r\nNow when you run the code, you will not find \\x9C\\x00\\x044\\x00\\x00\\x00\\x00 in output even though it still matches filter criteria. \r\n{quote}\r\n\r\nVerified the issue on master.\r\n"
    ],
    [
        "HBASE-12132",
        "HBASE-2083",
        "mvn install -Dtest=<testclass> also runs the hbase-it tests.  mvn install -Dtest=<testclass> runs tests in it and they time out. This Jira is intended to fix that behavior. ",
        "[EC2] HDFS DataNode no longer required on master "
    ],
    [
        "HBASE-13364",
        "HBASE-1999",
        "Make using the default javac on by default Errorprone doesn't work with java 8 and java 8 is becoming more and more standard everywhere.",
        "When HTable goes away, close zk session in shutdown hook or something... Currently, while there is a close on HTable, it does not let go of the zk session.. it does not call close... because the session is shared by all HTables in the VM.  Add a shutdown hook that will close zk on the way out.   Otherwise it makes for session timeouts in zk server logs."
    ],
    [
        "HBASE-10947",
        "HBASE-1200",
        "Allow subclassing of HTable and HBaseAdmin To extend functionality of HTable and HBaseAdmin we may need to subclass them. This JIRA allows to add a default constructor and probably remove the final variables in them so that we could subclass them.",
        "Add bloomfilters Add bloomfiltering to hfile.  Can be enabled on a family-level basis.  Ability to configure a row vs row+col level bloom.  We size the bloomfilter with the number of entries we are about to flush which seems like usually we'd be making a filter too big, so our implementation needs to take that into account."
    ],
    [
        "HBASE-6378",
        "HBASE-3976",
        "the javadoc of  setEnabledTable maybe not describe accurately    /**\r\n   * Sets the ENABLED state in the cache and deletes the zookeeper node. Fails\r\n   * silently if the node is not in enabled in zookeeper\r\n   * \r\n   * @param tableName\r\n   * @throws KeeperException\r\n   */\r\n  public void setEnabledTable(final String tableName) throws KeeperException {\r\n    setTableState(tableName, TableState.ENABLED);\r\n  }\r\n\r\nWhen setEnabledTable occours ,It will update the cache and the zookeeper node,rather than to delete the zk node.\r\n",
        "Disable Block Cache On Compactions Is there a good reason to believe that caching blocks during compactions is beneficial? Currently, if block cache is enabled on a certain family, then every time it's compacted, we load all of its blocks into the (LRU) cache, at the expense of the legitimately hot ones.\r\n\r\nAs a matter of fact, this concern was raised earlier in HBASE-1597, which rightly points out that, \"we should not bog down the LRU with unneccessary blocks\" during compaction. Even though that issue has been marked as \"fixed\", it looks like it ought to be reopened.\r\n\r\nShould we err on the side of caution and not cache blocks during compactions period (as illustrated in the attached patch)? Or, can we be selectively aggressive about what blocks do get cached during compaction (e.g., only cache those blocks from the recent files)?"
    ],
    [
        "HBASE-11659",
        "HBASE-2111",
        "Region state RPC call is not idempotent Here is the scenario on 0.98 with zk-less assignment\r\nThe master gets an OPEN RPC call from region server.\r\nSo, it moves the region state from PENDING_OPEN to OPEN.\r\nBut, the call timeouts on the region server and region server retries sending the OPEN call. However, now the master throws an Exception saying the region is not PENDING_OPEN. So, the region servers aborts the region on receiving that exception and sends FAILED_OPEN to master. But the master cannot change its state from FAILED_OPEN to OPEN, so eventually the master keeps the state as OPEN while the actual region is no longer open on region server.\r\n\r\nThe master should not throw an exception on receiving OPEN RPC calls multiple times.",
        "Move to ivy broke our being able to run in-place; i.e. ./bin/start-hbase.sh in a checkout. "
    ],
    [
        "HBASE-11667",
        "HBASE-5769",
        "Comment ClientScanner logic for NSREs. We ran into an issue with Phoenix where a RegionObserver coprocessor intercepts a scan and returns an aggregate (in this case a count) with a fake row key. It turns out this does not work when the {{ClientScanner}} encounters NSREs, as it uses the last key it saw to reset the scanner to try again (which in this case would be the fake key).\r\n\r\nWhile this is arguably a rare case and one could also argue that a region observer just shouldn't do this... While looking at {{ClientScanner}}'s code I found this logic not necessary.\r\nA NSRE occurred because we contacted a region server with a key that it no longer hosts. This is the start key, so it is always correct to retry with this same key. That simplifies the ClientScanner logic and also make this sort of coprocessors possible,",
        "Use builder pattern to create HServerLoad.RegionLoad Currently, HRegionServer.createRegionLoad() calls RegionLoad ctor with all the parameters.\r\nThis makes adding new members to RegionLoad tedious.\r\n\r\nBuilder pattern should be employed to create HServerLoad.RegionLoad"
    ],
    [
        "HBASE-12819",
        "HBASE-7104",
        "ExportSnapshot doesn't close FileSystem instances While troubleshooting an out of memory error exporting snapshot to s3a, I found that ExportSnapshot doesn't close FileSystem instances it uses.\r\n\r\nAn implementation (s3a e.g.) may depend on close() call so that resources are released.\r\nExportSnapshot should close the FileSystem instances upon exit.",
        "HBase includes multiple versions of netty: 3.5.0; 3.2.4; 3.2.2 We've got 3 of them on trunk.\r\n\r\n[INFO] org.apache.hbase:hbase-server:jar:0.95-SNAPSHOT\r\n[INFO] +- io.netty:netty:jar:3.5.0.Final:compile\r\n[INFO] +- org.apache.zookeeper:zookeeper:jar:3.4.3:compile\r\n[INFO] |  \\- org.jboss.netty:netty:jar:3.2.2.Final:compile\r\n\r\n[INFO] org.apache.hbase:hbase-hadoop2-compat:jar:0.95-SNAPSHOT\r\n[INFO] +- org.apache.hadoop:hadoop-client:jar:2.0.2-alpha:compile\r\n[INFO] |  +- org.apache.hadoop:hadoop-mapreduce-client-app:jar:2.0.2-alpha:compile\r\n[INFO] |  |  \\- org.jboss.netty:netty:jar:3.2.4.Final:compile\r\n\r\n\r\nThe patch attached:\r\n- fixes this for hadoop 1 profile\r\n- bump the netty version to 3.5.9\r\n- does not fix it for hadoop 2. I don't know why, but I haven't investigate: as it's still alpha may be they will change the version on hadoop side anyway.\r\n\r\nTests are ok.\r\n\r\nI haven't really investigated the differences between netty 3.2 and 3.5. A quick search seems to say it's ok, but don't hesitate to raise a warning..."
    ],
    [
        "HBASE-3190",
        "HBASE-1961",
        "Problem with disabling and droping table Table disabling was interrupted by kill -9 all part of hbase and now we cannot do anything with this table, disabling doesn't show any exception:\r\nhbase(main):019:0> disable 'NGolden_CTU'\r\n0 row(s) in 0.0250 seconds\r\n\r\n\r\nbut droping show this:\r\nhbase(main):020:0> drop 'NGolden_CTU'   \r\n\r\nERROR: org.apache.hadoop.hbase.TableNotDisabledException: org.apache.hadoop.hbase.TableNotDisabledException: NGolden_CTU\r\n        at org.apache.hadoop.hbase.master.HMaster.checkTableModifiable(HMaster.java:861)\r\n        at org.apache.hadoop.hbase.master.handler.TableEventHandler.<init>(TableEventHandler.java:52)\r\n        at org.apache.hadoop.hbase.master.handler.DeleteTableHandler.<init>(DeleteTableHandler.java:42)\r\n        at org.apache.hadoop.hbase.master.HMaster.deleteTable(HMaster.java:779)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\r\n        at java.lang.reflect.Method.invoke(Method.java:597)\r\n        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:570)\r\n        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1025)\r\n\r\nHere is some help for this command:\r\n          Drop the named table. Table must first be disabled. If table has\r\n          more than one region, run a major compaction on .META.:\r\n\r\n          hbase> major_compact \".META.\"\r\n\r\nafter this nothing strange is in logs\r\n\r\nwhen we restart hbase we get this:\r\n\r\n2010-11-03 08:56:37,892 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Processing open of NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.                                                        \r\n2010-11-03 08:56:37,892 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780005 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING                                                         \r\n2010-11-03 08:56:37,892 ERROR org.apache.hadoop.hbase.executor.EventHandler: Caught throwable while processing event M_RS_OPEN_REGION                                                                                                                                                  \r\njava.lang.NullPointerException                                                                                                                                                                                                                                                         \r\n        at org.apache.hadoop.hbase.util.Writables.getWritable(Writables.java:75)                                                                                                                                                                                                       \r\n        at org.apache.hadoop.hbase.executor.RegionTransitionData.fromBytes(RegionTransitionData.java:198)                                                                                                                                                                              \r\n        at org.apache.hadoop.hbase.zookeeper.ZKAssign.transitionNode(ZKAssign.java:669)                                                                                                                                                                                                \r\n        at org.apache.hadoop.hbase.zookeeper.ZKAssign.transitionNodeOpening(ZKAssign.java:549)                                                                                                                                                                                         \r\n        at org.apache.hadoop.hbase.zookeeper.ZKAssign.transitionNodeOpening(ZKAssign.java:542)                                                                                                                                                                                         \r\n        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.transitionZookeeperOfflineToOpening(OpenRegionHandler.java:208)                                                                                                                                              \r\n        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process(OpenRegionHandler.java:89)                                                                                                                                                                           \r\n        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:151)                                                                                                                                                                                                    \r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)                                                                                                                                                                                         \r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)                                                                                                                                                                                             \r\n        at java.lang.Thread.run(Thread.java:619)                                                                              \r\n\r\n\r\n\r\nOther logs with this region:\r\n\r\nhbase@db2a:logs$ grep \"0c8579e52b0ea3f2dab5b6a857ad030b\" hbase-hbase-master-db2a.goldenline.pl.log \r\n2010-11-03 08:54:02,575 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12c10b5fb780002 Async create of unassigned node for 0c8579e52b0ea3f2dab5b6a857ad030b with OFFLINE state\r\n2010-11-03 08:54:03,555 DEBUG org.apache.hadoop.hbase.master.AssignmentManager$CreateUnassignedAsyncCallback: rs=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. state=OFFLINE, ts=1288770842575, server=db2a.goldenline.pl,60020,1288770551154\r\n2010-11-03 08:54:03,777 DEBUG org.apache.hadoop.hbase.master.AssignmentManager$ExistsUnassignedAsyncCallback: rs=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. state=OFFLINE, ts=1288770842575\r\n2010-11-03 08:54:42,836 INFO org.apache.hadoop.hbase.master.AssignmentManager: Regions in transition timed out:  NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. state=PENDING_OPEN, ts=1288770843777\r\n2010-11-03 08:54:42,836 INFO org.apache.hadoop.hbase.master.AssignmentManager: Region has been PENDING_OPEN for too long, reassigning region=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.\r\n2010-11-03 08:54:42,836 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Forcing OFFLINE; was=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. state=PENDING_OPEN, ts=1288770843777\r\n2010-11-03 08:54:42,836 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: No previous transition plan was found (or we are ignoring an existing plan) for NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. so generated a random one; hri=NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b., src=, dest=db2b.goldenline.pl,60020,1288770553679; 2 (online=2, exclude=null) available servers\r\n2010-11-03 08:54:42,836 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Assigning region NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. to db2b.goldenline.pl,60020,1288770553679\r\n2010-11-03 08:56:12,824 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=db2a.goldenline.pl,60020,1288770551154, region=0c8579e52b0ea3f2dab5b6a857ad030b\r\n2010-11-03 08:56:12,975 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENED, server=db2a.goldenline.pl,60020,1288770551154, region=0c8579e52b0ea3f2dab5b6a857ad030b\r\n2010-11-03 08:56:12,976 DEBUG org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Handling OPENED event for 0c8579e52b0ea3f2dab5b6a857ad030b; deleting unassigned node\r\n2010-11-03 08:56:12,976 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12c10b5fb780002 Deleting existing unassigned node for 0c8579e52b0ea3f2dab5b6a857ad030b that is in expected state RS_ZK_REGION_OPENED\r\n2010-11-03 08:56:12,978 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12c10b5fb780002 Successfully deleted unassigned node for region 0c8579e52b0ea3f2dab5b6a857ad030b in expected state RS_ZK_REGION_OPENED\r\n2010-11-03 08:56:13,011 DEBUG org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Opened region NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. on db2a.goldenline.pl,60020,1288770551154\r\n\r\n\r\n\r\n\r\n\r\nhbase@db2a:logs$ grep \"0c8579e52b0ea3f2dab5b6a857ad030b\" hbase-hbase-regionserver-db2a.goldenline.pl.log \r\n2010-11-03 08:54:04,470 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Received request to open region: NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.\r\n2010-11-03 08:56:12,770 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Processing open of NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.\r\n2010-11-03 08:56:12,770 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING\r\n2010-11-03 08:56:12,819 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Successfully transitioned node 0c8579e52b0ea3f2dab5b6a857ad030b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING\r\n2010-11-03 08:56:12,819 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Opening region: REGION => {NAME => 'NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.', STARTKEY => '3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E', ENDKEY => '3065-d_2010_9_11_47D955785DEC3CE95377D70F67BA5ABC', ENCODED => 0c8579e52b0ea3f2dab5b6a857ad030b, TABLE => {{NAME => 'NGolden_CTU', FAMILIES => [{NAME => 'c', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', COMPRESSION => 'LZO', VERSIONS => '1', TTL => '-1', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}]}}\r\n2010-11-03 08:56:12,819 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Instantiated NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.\r\n2010-11-03 08:56:12,939 INFO org.apache.hadoop.hbase.regionserver.StoreFile$Reader: Loaded row bloom filter metadata for hdfs://db2a:50001/hbase/NGolden_CTU/0c8579e52b0ea3f2dab5b6a857ad030b/c/561636411807463667\r\n2010-11-03 08:56:12,939 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://db2a:50001/hbase/NGolden_CTU/0c8579e52b0ea3f2dab5b6a857ad030b/c/561636411807463667, isReference=false, isBulkLoadResult=false, seqid=1820373362, majorCompaction=true\r\n2010-11-03 08:56:12,939 INFO org.apache.hadoop.hbase.regionserver.HRegion: Onlined NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.; next sequenceid=1820373363\r\n2010-11-03 08:56:12,939 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING\r\n2010-11-03 08:56:12,970 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Successfully transitioned node 0c8579e52b0ea3f2dab5b6a857ad030b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENING\r\n2010-11-03 08:56:12,971 INFO org.apache.hadoop.hbase.catalog.MetaEditor: Updated row NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b. in region .META.,,1 with server=db2a.goldenline.pl:60020, startcode=1288770551154\r\n2010-11-03 08:56:12,971 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED\r\n2010-11-03 08:56:12,973 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780001 Successfully transitioned node 0c8579e52b0ea3f2dab5b6a857ad030b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED\r\n2010-11-03 08:56:12,973 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Opened NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.\r\n\r\n\r\n\r\n\r\nhbase@db2b:logs$  grep \"0c8579e52b0ea3f2dab5b6a857ad030b\" hbase-hbase-regionserver-db2b.goldenline.pl.log\r\n2010-11-03 08:54:42,840 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Received request to open region: NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.\r\n2010-11-03 08:56:37,892 DEBUG org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Processing open of NGolden_CTU,3065-d_2010_10_14_245FF1A15F4E236002ED3AB651BAB97E,1288046281444.0c8579e52b0ea3f2dab5b6a857ad030b.\r\n2010-11-03 08:56:37,892 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: regionserver:60020-0x12c10b5fb780005 Attempting to transition node 0c8579e52b0ea3f2dab5b6a857ad030b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING\r\n",
        "HBase EC2 scripts Attached tarball is a clone of the Hadoop EC2 scripts, modified significantly to start up a HBase storage only cluster on top of HDFS backed by instance storage. \r\n\r\nTested with the HBase 0.20 branch but should work with trunk also. Only the AMI create and launch scripts are tested. Will bring up a functioning HBase cluster. \r\n\r\nDo \"create-hbase-image c1.xlarge\" to create an x86_64 AMI, or \"create-hbase-image c1.medium\" to create an i386 AMI.  Public Hadoop/HBase 0.20.1 AMIs are available:\r\n    i386: ami-c644a7af\r\n    x86_64: ami-f244a79b\r\n\r\nlaunch-hbase-cluster brings up the cluster: First, a small dedicated ZK quorum, specifiable in size, default of 3. Then, the DFS namenode (formatting on first boot) and one datanode and the HBase master. Then, a specifiable number of slaves, instances running DFS datanodes and HBase region servers.  For example:\r\n\r\n{noformat}\r\n    launch-hbase-cluster testcluster 100 5\r\n{noformat}\r\n\r\nwould bring up a cluster with 100 slaves supported by a 5 node ZK ensemble.\r\n\r\nWe must colocate a datanode with the namenode because currently the master won't tolerate a brand new DFS with only namenode and no datanodes up yet. See HBASE-1960. By default the launch scripts provision ZooKeeper as c1.medium and the HBase master and region servers as c1.xlarge. The result is a HBase cluster supported by a ZooKeeper ensemble. ZK ensembles are not dynamic, but HBase clusters can be grown by simply starting up more slaves, just like Hadoop. \r\n\r\nhbase-ec2-init-remote.sh can be trivially edited to bring up a jobtracker on the master node and task trackers on the slaves."
    ],
    [
        "HBASE-12617",
        "HBASE-1817",
        "Running IntegrationTestBigLinkedList against cluster getting not an instance of org.apache.hadoop.hbase.MiniHBaseCluster Running integration test against cluster I'm getting this on tip of branch-1:\r\n\r\n{code}\r\n2014-12-02 15:51:37,193 ERROR [main] util.AbstractHBaseTool: Error running command-line tool\r\njava.lang.RuntimeException: org.apache.hadoop.hbase.DistributedHBaseCluster@7103cb56 not an instance of org.apache.hadoop.hbase.MiniHBaseCluster\r\n\tat org.apache.hadoop.hbase.HBaseTestingUtility.getMiniHBaseCluster(HBaseTestingUtility.java:952)\r\n\tat org.apache.hadoop.hbase.HBaseTestingUtility.getConnection(HBaseTestingUtility.java:2494)\r\n\tat org.apache.hadoop.hbase.HBaseTestingUtility.getHBaseAdmin(HBaseTestingUtility.java:2514)\r\n\tat org.apache.hadoop.hbase.IntegrationTestingUtility.createDistributedHBaseCluster(IntegrationTestingUtility.java:141)\r\n\tat org.apache.hadoop.hbase.IntegrationTestingUtility.initializeCluster(IntegrationTestingUtility.java:75)\r\n\tat org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.setUpCluster(IntegrationTestBigLinkedList.java:1104)\r\n\tat org.apache.hadoop.hbase.IntegrationTestBase.setUp(IntegrationTestBase.java:124)\r\n\tat org.apache.hadoop.hbase.IntegrationTestBase.doWork(IntegrationTestBase.java:109)\r\n\tat org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:114)\r\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\r\n\tat org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.main(IntegrationTestBigLinkedList.java:1225)\r\n{code}\r\n\r\nIt looks like this was broken by:\r\n\r\n{code}\r\n   1 commit c0cdaf8400831bada22558febbab9681f606e26c\r\n   2 Author: stack <stack@apache.org>\r\n   3 Date:   Tue Nov 25 12:26:54 2014 -0800\r\n   4\r\n   5         HBASE-12404 Task 5 from parent: Replace internal HTable constructor use with\r\n   6         HConnection#getTable (0.98, 0.99)\r\n{code}\r\n\r\nWe used to create an HBaseAdmin internally with  managed connection but we changed it to use the HTU's admin.  In the patch we added check that there is a HTU cluster up and running -- a mini cluster -- but there won't be in the case of an IT test going against a cluster.",
        "Add to package documentation the need of zk to be in classpath Add to package documentation the need of zk to be in classpath as of 0.20.0"
    ],
    [
        "HBASE-9366",
        "HBASE-9567",
        "TestHTraceHooks.testTraceCreateTable ConcurrentModificationException up in htrace lib See http://jenkins-public.iridiant.net/job/HBase-0.95/898/org.apache.hbase$hbase-server/testReport/junit/org.apache.hadoop.hbase.trace/TestHTraceHooks/testTraceCreateTable/\r\n\r\n{code}\r\nRegression\r\n\r\norg.apache.hadoop.hbase.trace.TestHTraceHooks.testTraceCreateTable\r\n\r\nFailing for the past 1 build (Since Failed#898 )\r\nTook 43 ms.\r\nStacktrace\r\n\r\njava.util.ConcurrentModificationException\r\n\tat java.util.HashMap$HashIterator.nextEntry(HashMap.java:793)\r\n\tat java.util.HashMap$KeyIterator.next(HashMap.java:828)\r\n\tat org.cloudera.htrace.TraceTree.<init>(TraceTree.java:48)\r\n\tat org.apache.hadoop.hbase.trace.TestHTraceHooks.testTraceCreateTable(TestHTraceHooks.java:108)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\r\n\tat java.lang.reflect.Method.invoke(Method.java:597)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)\r\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)\r\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\r\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:309)\r\n\tat org.junit.runners.Suite.runChild(Suite.java:127)\r\n\tat org.junit.runners.Suite.runChild(Suite.java:26)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)\r\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)\r\n\tat java.lang.Thread.run(Thread.java:662)\r\n{code}\r\n\r\nAssigning Elliott.  He has keys to the htrace kingdom.",
        "Make room for additional encodings in OrderedBytes I'd like to make a little more room in the OrderedBytes header byte. Also, reserve two values for HBASE-9369."
    ],
    [
        "HBASE-214",
        "HBASE-14700",
        "Compaction errors after a region splits I am getting compaction errors from regions after they split not all of them have this problem but some do\n\nI attached a log I picked out one region webdata,com.technorati/tag/potiron:http,1200430376177\n\nit is loaded then splits at \n2008-01-15 14:52:56,116\n\nthe split is finshed at\n2008-01-15 14:53:01,653\n\nthe first compaction for the new top half region starts at\n2008-01-15 14:54:07,612 - webdata,com.technorati/tag/potiron:http,1200430376177\n\nand ends successful at\n2008-01-15 14:54:30,229\n\nten the next compaction starts at\n2008-01-15 14:56:16,315\n\nThis one ends with an error at \n2008-01-15 14:56:40,246\n\n{code}\n2008-01-15 14:57:53,002 ERROR org.apache.hadoop.hbase.HRegionServer: Compaction failed for region webdata,com.technorati/tag/potiron:http,1200430376177\norg.apache.hadoop.dfs.LeaseExpiredException: org.apache.hadoop.dfs.LeaseExpiredException: No lease on /gfs_storage/hadoop-root/hbase/webdata/compaction.dir/1438658724/in_rank/mapfiles/8222904438849251562/data\n\tat org.apache.hadoop.dfs.FSNamesystem.checkLease(FSNamesystem.java:1123)\n\tat org.apache.hadoop.dfs.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1061)\n\tat org.apache.hadoop.dfs.NameNode.addBlock(NameNode.java:303)\n\tat sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:585)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:409)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:908)\n\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:494)\n\tat org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:82)\n\tat org.apache.hadoop.hbase.RemoteExceptionHandler.checkIOException(RemoteExceptionHandler.java:48)\n\tat org.apache.hadoop.hbase.HRegionServer$Compactor.run(HRegionServer.java:418)\n{code}\n\nand all other compaction's for this region fail after this one fail with the same error I will have to keep testing to see if it ever finishes successfully. \nmaybe after a restart it will successfully finsh a compaction.\n\n",
        "Support a \"permissive\" mode for secure clusters to allow \"simple\" auth clients When implementing HBase security for an existing cluster, it can be useful to support mixed secure and insecure clients while all client configurations are migrated over to secure authentication.  \r\n\r\nWe currently have an option to allow secure clients to fallback to simple auth against insecure clusters.  By providing an analogous setting for servers, we would allow a phased rollout of security:\r\n# First, security can be enabled on the cluster servers, with the \"permissive\" mode enabled\r\n# Clients can be converting to using secure authentication incrementally\r\n# The server audit logs allow identification of clients still using simple auth to connect\r\n# Finally, when sufficient clients have been converted to secure operation, the server-side \"permissive\" mode can be removed, allowing completely secure operation.\r\n\r\nObviously with this enabled, there is no effective access control, but this would still be a useful tool to enable a smooth operational rollout of security.  Permissive mode would of course be disabled by default.  Enabling it should provide a big scary warning in the logs on startup, and possibly be flagged on relevant UIs."
    ],
    [
        "HBASE-1508",
        "HBASE-6761",
        "Shell \"close_region\" reveals a Master<>HRS problem, regions are not reassigned When issuing a \"close_region\" on the shell the Master logs these entries:\r\n\r\n{code}\r\n...\r\n2009-06-09 22:11:31,141 DEBUG org.apache.hadoop.hbase.master.RegionManager: Applying operation in tasklists to region\r\n2009-06-09 22:11:33,557 DEBUG org.apache.hadoop.hbase.master.HMaster: Attempting to close region: TestTable,0000291328,1244572849139\r\n2009-06-09 22:11:33,560 INFO org.apache.hadoop.hbase.master.HMaster: Marking TestTable,0000291328,1244572849139 as closed on 192.168.2.103:63745; cleaning SERVER + STARTCODE; master will tell regionserver to close region on next heartbeat\r\n2009-06-09 22:11:34,156 DEBUG org.apache.hadoop.hbase.master.RegionManager: Applying operation in tasklists to region\r\n...\r\n{code}\r\n\r\nBut that is it, no further processing is done. The regions stays closed, and even across a restart it stays closed. \r\n\r\nAccording to what I got told the region should be automatically reassigned to a new server. Please confirm that this is what is expected. If not and the above seems right, then please disregard and close issue.",
        "secure build is failing: \"cannot find symbol symbol  : constructor Invocation(java.lang.reflect.Method,java.lang.Object[])\" HBASE-6340 udpated Invocation.java but did not to update SecureRpcEngine with the signature changes."
    ],
    [
        "HBASE-4507",
        "HBASE-2185",
        "Create checkAndPut variant that exposes timestamp / UUID Michael checked the checkAndPut which doesn't expose timestamp. A variant of checkAndPut should be created to expose timestamp which is written into a column specified by additional parameters.",
        "Add html version of default hbase-site.xml  In the hadoop getting started page - there is a html version of the default configuration (of core-site.xml / hdfs-site.xml / mapred-site.xml ) . \r\n\r\nIt would be useful to have such a page for hbase-default.xml for easy reference without flipping the editors. \r\n\r\npatch creates a html file from the default hbase-default.xml usign xslt. \r\n\r\nnew target - conf.gen.html - added. \r\n\r\nsample run \r\n\r\n$ ant conf.gen.html\r\nBuildfile: build.xml\r\n\r\ninit:\r\n\r\nconf.gen.html:\r\n     [xslt] Processing /opt/workspace/remote-ws/hbase/conf/hbase-default.xml to /opt/workspace/remote-ws/hbase/build/hbase-site.html\r\n     [xslt] Loading stylesheet /opt/workspace/remote-ws/hbase/docs/conf2html.xsl\r\n     [echo] HTML Format of default HBase configuration available at /opt/workspace/remote-ws/hbase/build/hbase-site.html\r\n\r\nBUILD SUCCESSFUL\r\n\r\n"
    ],
    [
        "HBASE-3952",
        "HBASE-8215",
        "Guava snuck back in as a dependency via hbase-3777 Undo it as we did in HBASE-3264.",
        "Removing existing .regioninfo in writeRegioninfoOnFilesystem If HRegion#writeRegioninfoOnFilesystem:\r\n\r\n{code}\r\n    if (fs.exists(regioninfoPath) &&\r\n        fs.getFileStatus(regioninfoPath).getLen() > 0) {\r\n      return;\r\n    }\r\n{code}\r\n\r\nIf the file exists and its length is 0, the file should be removed.  This issue has been fixed in trunk with HBASE-7807.  We need to fix it in 0.94 as well. Otherwise, we will get this error:\r\n\r\n{noformat}\r\n2013-03-27 16:57:27,143 ERROR org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Failed open of region=t1,r4_38,1364392356229.dec30602f4805a3e640871185ae900aa.\r\njava.io.IOException: Unable to rename hdfs://hbase-6.ent.cloudera.com:17020/hbase/t1/dec30602f4805a3e640871185ae900aa/.tmp/.regioninfo to hdfs://hbase-6.ent.cloudera.com:17020/hbase/t1/dec30602f4805a3e640871185ae900aa/.regioninfo\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.checkRegioninfoOnFilesystem(HRegion.java:639)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.initialize(HRegion.java:426)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:3308)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:3256)\r\n\tat org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.openRegion(OpenRegionHandler.java:331)\r\n\tat org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process(OpenRegionHandler.java:107)\r\n\tat org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:169)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\r\n\tat java.lang.Thread.run(Thread.java:662)\r\n{noformat}\r\n\r\nAnd the region can't be opened, so that stuck in transition.\r\n"
    ],
    [
        "HBASE-8372",
        "HBASE-12475",
        "Provide mutability to CompoundConfiguration In discussion of HBASE-8347, it was proposed that CompoundConfiguration should support mutability.\r\n\r\nThis can be done by consolidating ImmutableConfigMap's on first modification to CompoundConfiguration.",
        "local-master-backup.sh run exception Problem:\r\n./bin/local-master-backup.sh 2 3 5\r\n./bin/local-master-backup.sh: 79: /down/B.BigData/Hadoop/hbase-0.98.7-hadoop2/bin/hbase-config.sh: [[: not found\r\n./bin/local-master-backup.sh: 88: /down/B.BigData/Hadoop/hbase-0.98.7-hadoop2/bin/hbase-config.sh: [[: not found\r\nUsage: hbase-daemon.sh [--config <conf-dir>] (start|stop|restart|autorestart) <hbase-command> <args...>\r\nUsage: hbase-daemon.sh [--config <conf-dir>] (start|stop|restart|autorestart) <hbase-command> <args...>\r\n\r\nFix\r\n1\\Remove [ or ]\r\n2\\bin/local-master-backup.sh start 2 3 5"
    ],
    [
        "HBASE-8084",
        "HBASE-11423",
        "Sundry mapreduce improvements Umbrella issue for a handful of improvements to the mapreduce infrastructure.",
        "Visibility label and per cell ACL feature not working with HTable#mutateRow() and MultiRowMutationEndpoint This is because pre/postBatchMutate() APIs are not getting called from HRegion#processRowsWithLocks()"
    ],
    [
        "HBASE-1923",
        "HBASE-5895",
        "Bulk incremental load into an existing table hbase-48 is about bulk load of a new table,maybe it's more practicable to bulk load aganist a existing table.\r\n",
        "Slow query log in trunk is too verbose Running a YCSB workload against trunk, the slow query log ends up logging the entire contents of \"mutate\" RPCs (in PB-encoded binary). This then makes the logging back up, which makes more slow queries, which makes the whole thing spin out of control. We should only summarize the RPC, rather than printing the whole contents."
    ],
    [
        "HBASE-12959",
        "HBASE-3198",
        " Compact never end when table's dataBlockEncoding using  PREFIX_TREE I upgraded the hbase from 0.96.1.1 to 0.98.7 and hadoop from 2.2.0 to 2.5.1,some table encoding using prefix-tree was abnormal for compacting,  the gui shows the table's Compaction status is MAJOR_AND_MINOR(MAJOR) all the time.\r\n\r\nin the regionserver dump , there are some logs as below:\r\n\r\n\r\nTasks:\r\n===========================================================\r\nTask: Compacting info in PREFIX_NOT_COMPACT,,1421954285670.41ef60e2c221772626e141d5080296c5.\r\nStatus: RUNNING:Compacting store info\r\nRunning for 1097s  (on the  site running more than 3 days)\r\n............................\r\n\r\nThread 197 (regionserver60020-smallCompactions-1421954341530):\r\n  State: RUNNABLE\r\n  Blocked count: 7\r\n  Waited count: 3\r\n  Stack:\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.followFan(PrefixTreeArrayScanner.java:329)\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtOrAfter(PrefixTreeArraySearcher.java:149)\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.seekForwardToOrAfter(PrefixTreeArraySearcher.java:183)\r\n    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToOrBeforeUsingPositionAtOrAfter(PrefixTreeSeeker.java:199)\r\n    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToKeyInBlock(PrefixTreeSeeker.java:162)\r\n    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.loadBlockAndSeekToKey(HFileReaderV2.java:1172)\r\n    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.reseekTo(HFileReaderV2.java:573)\r\n    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseekAtOrAfter(StoreFileScanner.java:257)\r\n    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseek(StoreFileScanner.java:173)\r\n    org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.doRealSeek(NonLazyKeyValueScanner.java:55)\r\n    org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:313)\r\n    org.apache.hadoop.hbase.regionserver.KeyValueHeap.reseek(KeyValueHeap.java:257)\r\n    org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(StoreScanner.java:697)\r\n    org.apache.hadoop.hbase.regionserver.StoreScanner.seekAsDirection(StoreScanner.java:683)\r\n    org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:533)\r\n    org.apache.hadoop.hbase.regionserver.compactions.Compactor.performCompaction(Compactor.java:222)\r\n    org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.compact(DefaultCompactor.java:77)\r\n    org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext.compact(DefaultStoreEngine.java:110)\r\n    org.apache.hadoop.hbase.regionserver.HStore.compact(HStore.java:1099)\r\n    org.apache.hadoop.hbase.regionserver.HRegion.compact(HRegion.java:1482)\r\n\r\nThread 177 (regionserver60020-smallCompactions-1421954314809):\r\n  State: RUNNABLE\r\n  Blocked count: 40\r\n  Waited count: 60\r\n  Stack:\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.column.ColumnReader.populateBuffer(ColumnReader.java:81)\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.populateQualifier(PrefixTreeArrayScanner.java:471)\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.populateNonRowFields(PrefixTreeArrayScanner.java:452)\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.nextRow(PrefixTreeArrayScanner.java:226)\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.advance(PrefixTreeArrayScanner.java:208)\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtQualifierTimestamp(PrefixTreeArraySearcher.java:244)\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtOrAfter(PrefixTreeArraySearcher.java:123)\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.seekForwardToOrAfter(PrefixTreeArraySearcher.java:183)\r\n    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToOrBeforeUsingPositionAtOrAfter(PrefixTreeSeeker.java:199)\r\n    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToKeyInBlock(PrefixTreeSeeker.java:162)\r\n    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.loadBlockAndSeekToKey(HFileReaderV2.java:1172)\r\n    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.reseekTo(HFileReaderV2.java:573)\r\n    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseekAtOrAfter(StoreFileScanner.java:257)\r\n    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseek(StoreFileScanner.java:173)\r\n    org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.doRealSeek(NonLazyKeyValueScanner.java:55)\r\n    org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:313)\r\n    org.apache.hadoop.hbase.regionserver.KeyValueHeap.reseek(KeyValueHeap.java:257)\r\n    org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(StoreScanner.java:697)\r\n    org.apache.hadoop.hbase.regionserver.StoreScanner.seekAsDirection(StoreScanner.java:683)\r\n    org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:533)\r\n\r\nThread 170 (regionserver60020-smallCompactions-1421954306575):\r\n  State: RUNNABLE\r\n  Blocked count: 40\r\n  Waited count: 46\r\n  Stack:\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.nextRowInternal(PrefixTreeArrayScanner.java:259)\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.nextRow(PrefixTreeArrayScanner.java:222)\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArrayScanner.advance(PrefixTreeArrayScanner.java:208)\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtQualifierTimestamp(PrefixTreeArraySearcher.java:244)\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.positionAtOrAfter(PrefixTreeArraySearcher.java:123)\r\n    org.apache.hadoop.hbase.codec.prefixtree.decode.PrefixTreeArraySearcher.seekForwardToOrAfter(PrefixTreeArraySearcher.java:183)\r\n    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToOrBeforeUsingPositionAtOrAfter(PrefixTreeSeeker.java:199)\r\n    org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeSeeker.seekToKeyInBlock(PrefixTreeSeeker.java:162)\r\n    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.loadBlockAndSeekToKey(HFileReaderV2.java:1172)\r\n    org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.reseekTo(HFileReaderV2.java:573)\r\n    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseekAtOrAfter(StoreFileScanner.java:257)\r\n    org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseek(StoreFileScanner.java:173)\r\n    org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.doRealSeek(NonLazyKeyValueScanner.java:55)\r\n    org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:313)\r\n    org.apache.hadoop.hbase.regionserver.KeyValueHeap.reseek(KeyValueHeap.java:257)\r\n    org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(StoreScanner.java:697)\r\n    org.apache.hadoop.hbase.regionserver.StoreScanner.seekAsDirection(StoreScanner.java:683)\r\n    org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:533)\r\n    org.apache.hadoop.hbase.regionserver.compactions.Compactor.performCompaction(Compactor.java:222)\r\n    org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.compact(DefaultCompactor.java:77)\r\n\r\n\r\n\r\nI also reproduce the appearance in the test env,actually the logs was fetch in my test env. \r\n\r\nschema :\r\ncreate 'PREFIX_NOT_COMPACT', {NAME=>'info',VERSIONS=>1,BLOCKCACHE => true,DATA_BLOCK_ENCODING => 'PREFIX_TREE', BLOOMFILTER => 'ROW', IN_MEMORY => 'false', REPLICATION_SCOPE => '0', COMPRESSION => 'LZ4',MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', TTL => '600'},SPLITS =>['20150202']\r\n\r\ndata :\r\n     see the attachments , load from the text data or storefiles.",
        "Log rolling archives files prematurely From the mailing list, Erdem Agaoglu found a case where when an HLog gets rolled from the periodic log roller and it gets archived even tho the region (ROOT) still has edits in the MemStore. I did an experiment on a local empty machine and it does look broken:\r\n\r\n{noformat}\r\norg.apache.hadoop.hbase.regionserver.LogRoller: Hlog roll period 6000ms elapsed\r\norg.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter: Using syncFs -- HDFS-200\r\norg.apache.hadoop.hbase.regionserver.wal.HLog: Roll /hbase-89-su/.logs/hbasedev,60020,1288977933643/10.10.1.177%3A60020.1288977933829, entries=1,\r\n filesize=295. New hlog /hbase-89-su/.logs/hbasedev,60020,1288977933643/10.10.1.177%3A60020.1288977943913\r\norg.apache.hadoop.hbase.regionserver.wal.HLog: Found 1 hlogs to remove  out of total 1; oldest outstanding sequenceid is 270055 from region -ROOT-,,0\r\norg.apache.hadoop.hbase.regionserver.wal.HLog: moving old hlog file /hbase-89-su/.logs/hbasedev,60020,1288977933643/10.10.1.177%3A60020.1288977933829\r\n whose highest sequenceid is 270054 to /hbase-89-su/.oldlogs/10.10.1.177%3A60020.1288977933829\r\n{noformat}\r\n\r\nMarking as Blocker and taking a deeper look."
    ],
    [
        "HBASE-4447",
        "HBASE-1862",
        "Allow hbase.version to be passed in as command-line argument Currently the build always produces the jars and tarball according to the version baked into the POM.\r\nWhen we modify this to allow the version to be passed in as a command-line argument, it can still default to the same behavior, yet give the flexibility for an internal build to tag on own version.",
        "[migration] Migration tools need to have the filesystem set for them Fellas are running into this:\r\n\r\n{code}\r\nException in thread \"main\" java.lang.IllegalArgumentException: Wrong FS: hdfs://testhbase01:9000/hbase-backup/-ROOT-/70236052/info/mapfiles, expected: file:///\r\n{code} \r\n\r\n.. when trying to use the migration tools in FSUtils and HRegion"
    ],
    [
        "HBASE-8555",
        "HBASE-4589",
        "FilterList correctness may be affected by random ordering of sub-filter(list) say, ther're 10 rows, column value is i%2:\r\nrow0 0\r\nrow1 1\r\nrow2 0\r\nrow3 1\r\nrow4 0\r\nrow5 1\r\nrow6 0\r\nrow7 1\r\nrow8 0\r\nrow9 1\r\n\r\n1: filter : row filter > row4   ===> row5 row6 row7 row8 row9\r\n2: subFilterList:  row filter <= row4 && column==0    ===> row0 row2 row4\r\n3.1 filterlist[expected]   filter || subFilterList  ===> row0 row2 row4 row5 row6 row7 row8 row9\r\n3.2 filterlist[BUGON!]  subFilterList || filter ===> row0 row1 row2 row3 row4 row5 row6 row7 row8 row9\r\n(Please refer to the new testNestedFilterListWithSCVF case)\r\n\r\nIt was found when i managed to transform the following SQL into HBase scan statement: \r\nselect xxx from xxx where (pk <= xxx and column1 = xxx) or pk > xxx\r\n\r\nMy finding is that we had an assumption for filter methods call sequence:\r\ne.g. filterRowKey() should be called before filterKeyValue().\r\nand the orignial filterList.filterRowKey impl broke it due to fast short-circuit returning.",
        "CacheOnWrite broken in some cases because it can conflict with evictOnClose Commit of HBASE-4078 added some extra StoreFile verification which just did an open of a StoreFile reader and then closes it, ensuring there's no exception.  If evict-on-close is on, which it is by default, this causes all blocks of a file to be evicted even though it's still open.\r\n\r\nWe need to add the boolean into the close call in the way we have booleans for cacheBlocks at some point since we need to make localized decisions in some cases.\r\n\r\nIn lots of places, we can always rely on cacheConf.shouldEvictOnClose() so shouldn't be too burdensome."
    ],
    [
        "HBASE-5585",
        "HBASE-15149",
        "Add a feature in shell to allow adding entries into META easily From IRC \r\n\r\n{noformat}\r\nsulabhc\tSt^Ack: that fixed most of the issue, just one last question, I removed some META entries how do I put it back ?\r\nsulabhc\tSt^Ack: putting from Hbase-shell does not seem to be possible\r\nSt^Ack\tsulabhc: it is but the content in .META. is serialized Writable of HRegionInfo.\r\nSt^Ack\tCan you find the region in the fs that you want to put back?\r\nSt^Ack\tIf so, cat its .regioninfo\r\nSt^Ack\tit has binary format of the HRegionInfo that needs to be in .META. and a txt version.\r\nSt^Ack \tYou'll need to create an HRegionInfo, serialize it as bytes, and then put that into .META.\r\nSt^Ack\tLook around in the catalog package, the MetaEditor class, for how to do this from java.\r\nSt^Ack\tWe should really make this easier to do in shell...\r\nSt^Ack\tor look in bin to see how we do some of this via (j)ruby\r\n{noformat}",
        "hadoopcheck precommit check should only run when compile is needed on HBASE-15145 we have a change that only changes shellcode. in cases like this, where we don't alter anything used in compilation, we should not run hadoopcheck."
    ],
    [
        "HBASE-13005",
        "HBASE-11621",
        "TestDeleteTableHandler failing in 0.98 hadoop 1 builds Stabilize the test or revert the change containing it.",
        "Make MiniDFSCluster run faster Daryn proposed the following change in HDFS-6773:\r\n\r\n{code}\r\nEditLogFileOutputStream.setShouldSkipFsyncForTesting(true);\r\n{code}\r\n\r\nWith this change in HBaseTestingUtility#startMiniDFSCluster(), runtime for TestAdmin went from 8:35 min to 7 min"
    ],
    [
        "HBASE-7115",
        "HBASE-668",
        "[shell] Provide a way to register custom filters with the Filter Language Parser HBASE-5428 added this capability to thrift interface but the configuration parameter name is \"thrift\" specific.\r\n\r\nThis patch introduces a more generic parameter \"hbase.user.filters\" using which the user defined custom filters can be specified in the configuration and loaded in any client that needs to use the filter language parser.\r\n\r\nThe patch then uses this new parameter to register any user specified filters while invoking the HBase shell.\r\n\r\nExample usage: Let's say I have written a couple of custom filters with class names *{{org.apache.hadoop.hbase.filter.custom.SuperDuperFilter}}* and *{{org.apache.hadoop.hbase.filter.custom.SilverBulletFilter}}* and I want to use them from HBase shell using the filter language.\r\n\r\nTo do that, I would add the following configuration to {{hbase-site.xml}}\r\n\r\n{panel}{{<property>}}\r\n{{\u00a0\u00a0<name>hbase.user.filters</name>}}\r\n{{\u00a0\u00a0<value>}}*{{SuperDuperFilter}}*{{:org.apache.hadoop.hbase.filter.custom.SuperDuperFilter,}}*{{SilverBulletFilter}}*{{:org.apache.hadoop.hbase.filter.custom.SilverBulletFilter</value>}}\r\n{{</property>}}{panel}\r\n\r\nOnce this is configured, I can launch HBase shell and use these filters in my {{get}} or {{scan}} just the way I would use a built-in filter.\r\n\r\n{code}\r\nhbase(main):001:0> scan 't', {FILTER => \"SuperDuperFilter(true) AND SilverBulletFilter(42)\"}\r\nROW                                                          COLUMN+CELL\r\n status                                                      column=cf:a, timestamp=304385520000, value=world_peace\r\n1 row(s) in 0.0000 seconds\r\n{code}\r\n\r\nTo use this feature in any client, the client needs to make the following function call as part of its initialization.\r\n{code}\r\nParseFilter.registerUserFilters(configuration);\r\n{code}",
        "HBASE-533 broke build Build was broken when I committed HBASE-533.  Bunch of tests started to fail (I didn't run tests before committing)."
    ],
    [
        "HBASE-9958",
        "HBASE-264",
        "Remove some array copy, change lock scope in locateRegion ",
        "hbase scanner api returns null row names, or skips row names if different column families do not have entries for some rows I'm attaching a test case that fails.\n\nI noticed that if I create a table with two column families, and start a scanner on a row which only has an entry for one column family, the scanner will skip ahead to the row name for which the other column family has an entry.\n\neg., if I insert rows so my table will look like this:\n{code}\nrow - a:a - b:b\naaa   a:1   nil\nbbb   a:2   b:2\nccc   a:3   b:3\n{code}\n\nThe scanner will tell me my table looks something like this:\n{code}\nrow - a:a - b:b\nbbb   a:1   b:2\nbbb   a:2   b:3\n{code}\n"
    ],
    [
        "HBASE-3355",
        "HBASE-4002",
        "Stopping a stopped cluster leaks an HMaster This is a very annoying bug, I have two clusters running on the same machine so I often stop the wrong one (both are for testing). When it happens, it leaves a HMaster running with this:\r\n\r\n{noformat}\r\n\r\n\"main\" prio=10 tid=0x0000000041dd3800 nid=0x55d5 in Object.wait() [0x00007f3c7165a000]\r\n   java.lang.Thread.State: TIMED_WAITING (on object monitor)\r\n\tat java.lang.Object.wait(Native Method)\r\n\t- waiting on <0x00007f3bac94f528> (a java.lang.Object)\r\n\tat org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getMaster(HConnectionManager.java:382)\r\n\t- locked <0x00007f3bac94f528> (a java.lang.Object)\r\n\tat org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:90)\r\n\tat org.apache.hadoop.hbase.master.HMasterCommandLine.stopMaster(HMasterCommandLine.java:160)\r\n\tat org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:104)\r\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)\r\n\tat org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:76)\r\n\tat org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1058)\r\n{noformat}\r\n\r\nAnd if I happen to restart that cluster right away, IT KILLS IT!",
        "Int array based skip list We can implement an AtomicIntegerArray based skip list, where the int values point to locations in a byte block structure.  This can be useful for testing against ConcurrentSkipListMap.  It can also be used in Lucene for the realtime terms dictionary."
    ],
    [
        "HBASE-4746",
        "HBASE-13267",
        "Use a random ZK client port in unit tests so we can run them in parallel The hard-coded ZK client port has long been a problem for running HBase test suite in parallel. The mini ZK cluster should run on a random free port, and that port should be passed to all parts of the unit tests that need to talk to the mini cluster. In fact, randomizing the port exposes a lot of places in the code where a new configuration is instantiated, and as a result the client tries to talk to the default ZK client port and times out.\r\n\r\nThe initial fix is for 0.89-fb, where it already allows to run unit tests in parallel in 10 minutes. A fix for the trunk will follow.",
        "Deprecate or remove isFileDeletable from SnapshotHFileCleaner The isFileDeletable method in SnapshotHFileCleaner became vestigial after HBASE-12627, lets remove it. "
    ],
    [
        "HBASE-14816",
        "HBASE-7809",
        "UI and Shell table/region split does not work; broke Hitting split in the UI in the table page or running split from shell does not work.   Nothing in master log.",
        "Refactor Split/Merge to use HRegionFileSystem Use the HRegionFileSystem for the fs operations."
    ],
    [
        "HBASE-7755",
        "HBASE-11825",
        "Experiment with LAB in BlockEndcoding I was looking at and profiling the BlockEncoding code to figure out how to make it faster. One issue that jumped out was we call ByteBuffer.allocate(...) for each single KV.\r\nAs an experiment I tried using the MemStoreLAB code to allocate those buffers.\r\n\r\nHere are some preliminary numbers, all scanning 10m rows (all in cache):\r\n* no encoding: 5.2s\r\n* FAST_DIFF without patch: 7.3s\r\n* FAST_DIFF with patch and small LAB: 4.1s\r\n* FAST_DIFF with patch and large LAB: 11s\r\n\r\nSo this is very sensitive to the right sizing of the LAB.\r\n\r\nNeed to do a bit more testing, but it seems that there is a chance to actually make scanning with block encoding faster than without!\r\n",
        "Create Connection and ConnectionManager This is further cleanup of the HBase interface for 1.0 after implementing the new Table and Admin interfaces.  Following Enis's guidelines in HBASE-10602, this JIRA will generate a new ConnectionManager to replace HCM and Connection to replace HConnection.\r\n\r\nFor more detail, this JIRA intends to implement this portion:\r\n\r\n{code}\r\ninterface Connection extends Closeable{\r\n  Table getTable(), and rest of HConnection methods \r\n  getAdmin()\r\n  // no deprecated methods (cache related etc)\r\n}\r\n\r\n@Deprecated\r\ninterface HConnection extends Connection {\r\n  @Deprecated\r\n  HTableInterface getTable()\r\n  // users are encouraged to use Connection\r\n}\r\n\r\nclass ConnectionManager {\r\n  createConnection(Configuration) // not sure whether we want a static factory method to create connections or a ctor\r\n}\r\n\r\n@Deprecated\r\nclass HCM extends ConnectionManager {\r\n  // users are encouraged to use ConnectionManager\r\n}\r\n{code}\r\n"
    ],
    [
        "HBASE-4030",
        "HBASE-4891",
        "LoadIncrementalHFiles fails with FileNotFoundException -- We've been seeing intermittent failures of calls to LoadIncrementalHFiles.  When this happens the node that made the call will see a FileNotFoundException such as this:\r\n\r\n2011-06-23 15:47:34.379566500 java.net.SocketTimeoutException: Call to s8.XXX/67.215.90.38:60020 failed on socket timeout exception: java.net.SocketTi\r\nmeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/67.215.90.51:51605 remo\r\nte=s8.XXX/67.215.90.38:60020]\r\n2011-06-23 15:47:34.379570500 java.io.FileNotFoundException: java.io.FileNotFoundException: File does not exist: /hfiles/2011/06/23/14/domainsranked/TopDomainsRan\r\nk.r3v5PRvK/handling/3557032074765091256\r\n2011-06-23 15:47:34.379573500   at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.openInfo(DFSClient.java:1602)\r\n2011-06-23 15:47:34.379573500   at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.<init>(DFSClient.java:1593)\r\n\r\n-- Over on the regionserver that was loading this we see that it attempted to load and hit a 60 second timeout:\r\n\r\n2011-06-23 15:45:54,634 INFO org.apache.hadoop.hbase.regionserver.Store: Validating hfile at hdfs://namenode.XXX/hfiles/2011/06/23/14/domainsranked/TopDomainsRank.r3v5PRvK/handling/3557032074765091256 for inclusion in store handling region domainsranked,368449:2011/0/03/23:category:ffffffff:com.zynga.static.fishville.facebook,1305890318961.d4925aca7852bed32613a509215d42b\r\n8.\r\n...\r\n2011-06-23 15:46:54,639 INFO org.apache.hadoop.hdfs.DFSClient: Failed to connect to /67.215.90.38:50010, add to deadNodes and continue\r\njava.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/67.215.90.38:42199 remote=/67.215.90.38:50010]\r\nat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\r\nat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)\r\nat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)\r\nat java.io.BufferedInputStream.fill(BufferedInputStream.java:218)\r\nat java.io.BufferedInputStream.read(BufferedInputStream.java:237)\r\nat java.io.DataInputStream.readShort(DataInputStream.java:295)\r\n\r\n-- We suspect this particular problem is a resource contention issue on our side.  However, the loading process proceeds to rename the file despite the failure:\r\n\r\n2011-06-23 15:46:54,657 INFO org.apache.hadoop.hbase.regionserver.Store: Renaming bulk load file hdfs://namenode.XXX/hfiles/2011/06/23/14/domainsranked/TopDomainsRank.r3v5PRvK/handling/3557032074765091256 to hdfs://namenode.XXX:8020/hbase/domainsranked/d4925aca7852bed32613a509215d42b8/handling/3615917062821145533\r\n\r\n-- And then the LoadIncrementalHFiles tries to load the hfile again:\r\n\r\n2011-06-23 15:46:55,684 INFO org.apache.hadoop.hbase.regionserver.Store: Validating hfile at hdfs://namenode.XXX/hfiles/2011/06/23/14/domainsranked/TopDomainsRank.r3v5PRvK/handling/3557032074765091256 for inclusion in store handling region domainsranked,368449:2011/05/03/23:category:ffffffff:com.zynga.static.fishville.facebook,1305890318961.d4925aca7852bed32613a509215d42b8.\r\n\r\n2011-06-23 15:46:55,685 DEBUG org.apache.hadoop.ipc.HBaseServer: IPC Server handler 147 on 60020, call bulkLoadHFile(hdfs://namenode.XXX/hfiles/2011/06/23/14/domainsranked/TopDomainsRank.r3v5PRvK/handling/3557032074765091256, [B@4224508b, [B@5e23f799) from 67.215.90.51:51856: error: java.io.FileNotFoundException: File does not exist: /hfiles/2011/06/23/14/domainsranked/TopDomainsRank.r3v5PRvK/handling/3557032074765091256\r\n\r\n-- This eventually leads to the load command failing.",
        "HTable.ClientScanner needs to clone the Scan object The ClientScanner can make some changes to the Scan object like setting a new start row when it gets an error, so if someone was reusing that object for a new scan thinking it would have the same properties, he/she would currently be wrong."
    ],
    [
        "HBASE-13319",
        "HBASE-3888",
        "Support 64-bits total row number in PerformanceEvaluation Currently the total row number in PerformanceEvaluation is 32 bits. It's not enough when testing a large hbase cluster using PerformanceEvaluation in mapreduce mode.\r\n\r\nSuggestions are welcomed~ Thanks",
        "book.xml - filled in architecture 'daemon' section  The 'daemon' section in architecture has been empty for a while.  \r\n\r\nFilled in an overview of what HMaster and HRegionServer do, with a brief overview of what their functional interfaces look like, along with a short description of their background processes.\r\n\r\n"
    ],
    [
        "HBASE-618",
        "HBASE-11955",
        "We always compact if 2 files, regardless of the compaction threshold setting We will always compact if there are two files in a store.  Here is an illustration from a loading run against 0.1.2 candidate:\n\n{code}\n2008-05-06 18:25:42,255 INFO org.apache.hadoop.hbase.HRegion: starting compaction on region category_rule_pricebin_statistics,,1210116131965\n2008-05-06 18:25:42,259 DEBUG org.apache.hadoop.hbase.HStore: started compaction of 2 files [329657396/confidence_interval/1251369679869294899, 329657396/confidence_interval/5238351815319958452] into /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/confidence_interval/mapfiles/6688946093979715350\n2008-05-06 18:25:46,223 DEBUG org.apache.hadoop.hbase.HStore: moving /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/confidence_interval/mapfiles/6688946093979715350 to /hbase/category_rule_pricebin_statistics/329657396/confidence_interval/mapfiles/6019580165435904305\n2008-05-06 18:25:46,329 DEBUG org.apache.hadoop.hbase.HStore: started compaction of 2 files [329657396/rule_id/4877828519309794708, 329657396/rule_id/3736239181369788409] into /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/rule_id/mapfiles/6451418039787481756\n2008-05-06 18:25:50,273 DEBUG org.apache.hadoop.hbase.HStore: moving /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/rule_id/mapfiles/6451418039787481756 to /hbase/category_rule_pricebin_statistics/329657396/rule_id/mapfiles/1365174520347083269\n2008-05-06 18:25:50,338 DEBUG org.apache.hadoop.hbase.HStore: started compaction of 2 files [329657396/hidden_variable/7348598912095388790, 329657396/hidden_variable/1402264537929464657] into /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/hidden_variable/mapfiles/7895992615693344978\n2008-05-06 18:25:54,103 DEBUG org.apache.hadoop.hbase.HStore: moving /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/hidden_variable/mapfiles/7895992615693344978 to /hbase/category_rule_pricebin_statistics/329657396/hidden_variable/mapfiles/4450886729060218942\n2008-05-06 18:25:54,155 DEBUG org.apache.hadoop.hbase.HStore: started compaction of 2 files [329657396/category_id/6976628214412388959, 329657396/category_id/8426537623290869905] into /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/category_id/mapfiles/4017716533879305176\n2008-05-06 18:25:57,698 DEBUG org.apache.hadoop.hbase.HStore: moving /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/category_id/mapfiles/4017716533879305176 to /hbase/category_rule_pricebin_statistics/329657396/category_id/mapfiles/657561173732096591\n2008-05-06 18:25:57,747 DEBUG org.apache.hadoop.hbase.HStore: started compaction of 2 files [329657396/price_bin_id/165701488423589566, 329657396/price_bin_id/5537046322320665760] into /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/price_bin_id/mapfiles/3214618236668106036\n2008-05-06 18:26:01,135 DEBUG org.apache.hadoop.hbase.HStore: moving /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/price_bin_id/mapfiles/3214618236668106036 to /hbase/category_rule_pricebin_statistics/329657396/price_bin_id/mapfiles/8727588456978537416\n2008-05-06 18:26:01,181 INFO org.apache.hadoop.hbase.HRegion: compaction completed on region category_rule_pricebin_statistics,,1210116131965 in 18sec\n{code}\n\nIn the above, the region has 6 families, each of which is being loaded fairly evenly.   Every time through we'll compact a store if two files, which just so happens to be most of the time in this case.",
        "Thrift annotated Comparators for TFilterV2 Annotated Comparators for Filters as a first step for CompareFilter derived filters"
    ],
    [
        "HBASE-4840",
        "HBASE-5052",
        "If I call split fast enough, while inserting, rows disappear.  I'll attach a unit test for this. Basically if you call split, while inserting data you can get to the point to where the cluster becomes unstable, or rows will  disappear.",
        "The path where a dynamically loaded coprocessor jar is copied on the local file system depends on the region name (and implicitly, the start key) When loading a coprocessor from hdfs, the jar file gets copied to a path on the local filesystem, which depends on the region name, and the region start key. The name is \"cleaned\", but not enough, so when you have filesystem unfriendly characters (/?:, etc), the coprocessor is not loaded, and an error is thrown"
    ],
    [
        "HBASE-8177",
        "HBASE-5646",
        "Improve javadoc to including more about table lock semantics (failure handling, canonical usage pattern, what the lock guards)  Currently, the semantics of the table locks require a bit of digging to get the failure handling, and to determine when to use them.  Simple additions to the javadoc would make it more convenient for devs whoe are considering using it and for reviewers when they are used.",
        "[findbugs] Investigate experimental warnings See https://builds.apache.org/job/PreCommit-HBASE-Build/1313//artifact/trunk/patchprocess/newPatchFindbugsWarnings.html\r\n\r\nanalyze and fix/exclude warnings in the experimental section."
    ],
    [
        "HBASE-11695",
        "HBASE-12501",
        "PeriodicFlusher and WakeFrequency issues We just ran into a flush storm caused by the PeriodicFlusher.\r\nMany memstore became eligible for flushing at exactly the same time, the effect we've seen is that the exact same region was flushed multiple times, because the flusher wakes up too often (every 10s). The jitter of 20s is larger than that and it takes some time to actually flush the memstore.\r\n\r\nHere's one example. We've seen 100's of these, monopolizing the flush queue and preventing \"important\" flushes from happening.\r\n\r\n{code}\r\n06-Aug-2014 20:11:56  [regionserver60020.periodicFlusher] INFO  org.apache.hadoop.hbase.regionserver.HRegionServer[1397]-- regionserver60020.periodicFlusher requesting flush for region tsdb,\\x00\\x00\\x0AO\\xCF* \\x00\\x00\\x01\\x00\\x01\\x1F\\x00\\x00\\x03\\x00\\x00\\x0C,1340147003629.ef4a680b962592de910d0fdeb376dfc2. after a delay of 13449\r\n06-Aug-2014 20:12:06  [regionserver60020.periodicFlusher] INFO  org.apache.hadoop.hbase.regionserver.HRegionServer[1397]-- regionserver60020.periodicFlusher requesting flush for region tsdb,\\x00\\x00\\x0AO\\xCF* \\x00\\x00\\x01\\x00\\x01\\x1F\\x00\\x00\\x03\\x00\\x00\\x0C,1340147003629.ef4a680b962592de910d0fdeb376dfc2. after a delay of 14060\r\n{code}\r\n\r\nSo we need to increase the period of the PeriodicFlusher to at least the random jitter, also increase the default random jitter (20s does not help with many regions).\r\n",
        "Update the HBase client to be Quorum aware With the integration of Quorum based WAL, the HBase client needs to locate the current leader to perform the operations. \r\n\r\nFiling a JIRA to track this effort."
    ],
    [
        "HBASE-12024",
        "HBASE-1038",
        "Fix javadoc warning There are a couple of javadoc warning\r\n\r\n{noformat}\r\n[WARNING] /home/th30z/asf/hbase/hbase-common/src/main/java/org/apache/hadoop/hbase/security/User.java:175: warning - @return tag has no arguments.\r\n[WARNING] Javadoc Warnings\r\n[WARNING] /home/th30z/asf/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionFactory.java:56: warning - End Delimiter } missing for possible See Tag in comment string: \"A non-instantiable class that manages creation of {@link Connection}s.\r\n[WARNING] Managing the lifecycle of the {@link Connection}s to the cluster is the responsibility of\r\n[WARNING] the caller.\r\n[WARNING] From this {@link Connection} {@link Table} implementations are retrieved\r\n[WARNING] with {@link Connection#getTable(TableName)}. Example:\r\n[WARNING] <pre>\r\n[WARNING] {@code\r\n[WARNING] Connection connection = ConnectionFactory.createConnection(config);\r\n[WARNING] Table table = connection.getTable(TableName.valueOf(\"table1\"));\r\n[WARNING] try {\r\n[WARNING] // Use the table as needed, for a single operation and a single thread\r\n[WARNING] } finally {\r\n[WARNING] table.close();\r\n[WARNING] connection.close();\r\n[WARNING] }\r\n[WARNING] </pre>\r\n[WARNING] \r\n[WARNING] Similarly, {@link Connection} also returns {@link RegionLocator} implementations.\r\n[WARNING] This class replaces {@link HConnectionManager}, which is now deprecated.\"\r\n[WARNING] /home/th30z/asf/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java:144: warning - End Delimiter } missing for possible See Tag in comment string: \"Create a new HConnection instance using the passed <code>conf</code> instance.\r\n[WARNING] <p>Note: This bypasses the usual HConnection life cycle management done by\r\n[WARNING] {@link #getConnection(Configuration)}. The caller is responsible for\r\n[WARNING] calling {@link HConnection#close()} on the returned connection instance.\r\n[WARNING] This is the recommended way to create HConnections.\r\n[WARNING] {@code\r\n[WARNING] HConnection connection = HConnectionManager.createConnection(conf);\r\n[WARNING] HTableInterface table = connection.getTable(\"mytable\");\r\n[WARNING] try {\r\n[WARNING] table.get(...);\r\n[WARNING] ...\r\n[WARNING] } finally {\r\n[WARNING] table.close();\r\n[WARNING] connection.close();\r\n[WARNING] }\"\r\n{noformat}",
        "Master should accept client feedback about inconsistencies in META Jim Firby: Clients should be able to say \"I've asked for a regions location 10 times now and Mr. Master, you've given me the same response ten times in a row and each time, the answer was wrong. Revisit any notion that said region is at said location\". Mr. Master would then go off and do something drastic like close and reassign the region."
    ],
    [
        "HBASE-7330",
        "HBASE-9946",
        "Security hooks missing in region server and master APIs.  Some of the APIs in Master and Region server are missing hooks to the coprocessors. So even if security is enabled, an unauthorized user can perform certain operations. \r\n\r\nThe following is the list of operations:\r\n\r\n1. HMaster.offline()\r\n2. HMaster.getHTableDescriptors()\r\n3. HMaster.getHTableDescriptors(List<String> tableNames)\r\n4. HRegionServer.getRegionInfo()\r\n5. HRegionInterface.getLastFlushTime()\r\n6. HRegionInterface.getStoreFileList(byte[] regionName, byte[] columnFamily)\r\n7. HRegionInterface.getStoreFileList(byte[] regionName, byte[][] columnFamilies)\r\n8. HRegionInterface.getStoreFileList(byte[] regionName\r\n9. HRegionInterface.lockRow(final byte [] regionName, final byte [] row)\r\n10. HRegionInterface.unlockRow(final byte [] regionName, final long lockId)\r\n11. HRegionInterface.getOnlineRegions()\r\n12. HRegionInterface.getHServerInfo()\r\n13. HRegionInterface.replicateLogEntries(HLog.Entry[] entries)\r\n14. HRegionInterface.stop()\r\n15. HRegionInterface.OpenRegions()\r\n16. HRegionInterface.closeRegion()\r\n",
        "Create a HBase C++ Thrift Client This is a task to create a native thrift C++ client for HBase when we change the RPC stack to Thrift in HBASE-9930."
    ],
    [
        "HBASE-2039",
        "HBASE-7360",
        "G1 GC issues Lets keep an issue where we report on g1 issues.  Lets keep list of crashes we see.\r\n\r\nI filed an issue up on bug parade.  Lets see if it becomes actual bug.  Below I note version of vm and the type of crash (Internal Error (nmethod.cpp:1981), pid=32319..... Its a 'fatal error').  It happens for me after 5-10 minutes when a loading test.  Same thing each time.\r\n\r\nG1 in 1.6 seems plain broke; crashes on use of stuff in concurrent utils package.\r\n\r\nDate Created: Thu Dec 10 13:33:04 MST 2009\r\n..\r\nSynopsis:    Running G1 GC, crashes with \" Internal Error (nmethod.cpp:1981), pid=32319...\"\r\nDescription:\r\n FULL PRODUCT VERSION :\r\njava version \"1.7.0-ea\"\r\nJava(TM) SE Runtime Environment (build 1.7.0-ea-b77)\r\nJava HotSpot(TM) 64-Bit Server VM (build 17.0-b05, mixed mode)\r\n\r\nFULL OS VERSION :\r\nFedora Core release 6 (Zod)\r\n\r\nEXTRA RELEVANT SYSTEM CONFIGURATION :\r\nHere are the JVM args:\r\n\r\n-XX:+HeapDumpOnOutOfMemoryError -XX:+UnlockExperimentalVMOptions -XX:+UseG1GC",
        "Snapshot 0.94 Backport  Backport snapshot code to 0.94\r\n\r\nThe main changes needed to backport the snapshot are related to the protobuf vs writable rpc.\r\n\r\nOffline Snapshot\r\n * HBASE-6610 HFileLink: Hardlink alternative for snapshot restore\r\n * HBASE-6765 Take a Snapshot interface\r\n** This patch is significantly different because of the RPC changes between 0.94/0.96\r\n * HBASE-6571 Generic multi-thread/cross-process error handling framework\r\n * HBASE-6353 Snapshots shell\r\n * HBASE-7107 Snapshot References Utils (FileSystem Visitor)\r\n * HBASE-6836 Offline snapshots\r\n * HBASE-6865 Snapshot File Cleaners\r\n * HBASE-6777 Snapshot Restore Interface\r\n** This patch is significantly different because of the RPC changes between 0.94/0.96\r\n * HBASE-6230 Clone/Restore Snapshots\r\n * HBASE-6802 Export Snapshot\r\n * HBASE-7240 Cleanup old snapshots on start\r\n * HBASE-7174 Refactor snapshot file cleaner cache to use Snapshot\r\n * HBASE-7367 Snapshot coprocessor and ACL security\r\n * HBASE-7311 Add snapshot information to hbase master webui\r\n** This patch is significantly different because of the RPC changes between 0.94/0.96\r\n * HBASE-7418 HFileLink flaky test\r\n * HBASE-7420 TestSnapshotExceptionSnare and TestWALReferenceTask missing test category annotation and failing TestCheckTestClasses\r\n * HBASE-7206 ForeignException framework v2 (simplifies and replaces HBASE-6571)\r\n * HBASE-7430 TestSnapshotDescriptionUtils break compaction/scanner tests (EnvironmentEdge issue)\r\n * HBASE-7436 Improve stack trace info dumped by ForeignExceptionSnare#rethrowException\r\n * HBASE-7339 Splitting an HFileLink causes region servers to go down.\r\n * HBASE-7439 HFileLink should not use the configuration from the Filesystem\r\n * HBASE-7452 Change ForeignExceptionListener#receive(String, FE)  to only be #receive(FE)\r\n * HBASE-7208 Transition Offline Snapshots to ForeignExceptions and Refactor for merge\r\n * HBASE-7207 Consolidate snapshot related classes into fewer packages\r\n * HBASE-7400 ExportSnapshot mapper closes the FileSystem\r\n * HBASE-7352 clone operation from HBaseAdmin can hang forever\r\n * HBASE-7294 Check for snapshot file cleaners on start\r\n * HBASE-7354 Snapshot Info/Debug Tool\r\n * HBASE-7423 HFileArchiver should not use the configuration from the Filesystem\r\n * HBASE-7453 HBASE-7423 snapshot followup\r\n * HBASE-7212 Globally Barriered Procedure Mechanism\r\n * HBASE-6864 Online snapshots scaffolding\r\n * HBASE-7321 Simple Flush Snapshot\r\n * HBASE-7496 TestZKProcedure fails interrmittently.\r\n * HBASE-7484 Fix Restore with schema changes\r\n * HBASE-7419 revisit hfilelink file name format\r\n * HBASE-7467 CleanerChore checkAndDeleteDirectory not deleting empty directories\r\n * HBASE-7214 CleanerChore logs too much, so much so it obscures all else that is going on\r\n * HBASE-7523 Snapshot attempt with the name of a previously taken snapshot fails sometimes.\r\n * HBASE-7480 Explicit message for not allowed snapshot on meta tables\r\n * HBASE-7537 .regioninfo not created by createHRegion()\r\n * HBASE-7535 Fix restore reference files\r\n * HBASE-7552 Pass bufferSize param to FileLinkInputStream constructor within FileLink.open method, and remove unnecessary import packages.\r\n * HBASE-7501 Introduce MetaEditor method that both adds and deletes rows in .META. table\r\n * HBASE-7365/HBASE-7389 Safer table creation and deletion using .tmp dir\r\n * HBASE-7547 Fix findbugs warnings in snapshot classes\r\n * HBASE-7548 Fix javadoc warnings in snapshot classes\r\n * HBASE-7538 Improve snapshot related error and exception messages\r\n * HBASE-7536 Add test that confirms that multiple concurrent snapshot requests are rejected\r\n * HBASE-7583 Fixes and cleanups\r\n * HBASE-7604 Remove duplicated code from HFileLink\r\n * HBASE-7616 NPE in ZKProcedure.nodeCreated\r\n * HBASE-7625 Remove duplicated logFSTree() from TestRestoreFlushSnapshotFromClient\r\n * HBASE-7627 UnsupportedOperationException in CatalogJanitor thread\r\n * HBASE-7622 Add table descriptor verification after snapshot restore\r\n * HBASE-7651 RegionServerSnapshotManager fails with CancellationException if previous snapshot fails in per region task\r\n * HBASE-7666 More logging improvements in online snapshots code\r\n * HBASE-7689 CloneTableHandler notify completion too early\r\n * HBASE-7699 Replace LOG.info() with LOG.debug() in FSUtils.listStatus()\r\n * HBASE-7703 Eventually all online snapshots failing due to Timeout at same regionserver.\r\n * HBASE-7720 Improve logging messages of failed snapshot attempts.\r\n * HBASE-7795 Race in the Restore Archiving\r\n * HBASE-7788 Fix flakey TestRestore*SnapshotFromClient#testCloneSnapshot\r\n * HBASE-7858 cleanup before merging snapshots branch to trunk\r\n * HBASE-7889 Fix javadoc warnings in snapshot classes\r\n * HBASE-7911 Remove duplicated code from CreateTableHandler\r\n * HBASE-7969 Rename HBaseAdmin#getCompletedSnapshots as HBaseAdmin#listSnapshots\r\n * HBASE-7299 TestMultiParallel fails intermittently in trunk builds "
    ],
    [
        "HBASE-14858",
        "HBASE-12622",
        "Clean up so core is ready for development on a recent version of c++ ",
        "user_permission should require global admin to display global and ns permissions user_permission check the user permission only on the table level (requiring at least a table-level admin)\r\nglobal and namespace permission listing is done without checking anything.\r\nbut only a global admins should be able to perform this operations."
    ],
    [
        "HBASE-6887",
        "HBASE-14395",
        "Convert security-related shell commands to use PB-based AccessControlService The security-related HBase shell commands (grant, revoke, user_permission) are still using the old CoprocessorProtocol-based AccessControllerProtocol endpoint for dynamic RPC.  These need to be converted to use the protocol buffer based AccessControlService interface added in HBASE-5448.",
        "Short circuit last byte check in CellUtil#matchingXXX methods for ByteBufferedCells "
    ],
    [
        "HBASE-2240",
        "HBASE-2911",
        "Balancer should not reassign (because of overloading) a region that was just opened I'm running a mapreduce job.  I see a region split and its daughters come on line and then 8 seconds later, master judges the regionserver overloaded and so closes the just-opened region.  This messes up clients.   They may have just picked up the new location for their row query and now its moved again and client has to go hunting anew. \r\n\r\nWe need to assign the vintage regions first.\r\n\r\nI'm going to change balancer slop.  Its not sloppy enough and balancing cuts in too early.",
        "[stargate] Fix JSON handling of META and ROOT While working on the HBase Explorer front end in Hue I found a few inconsistencies between the plain text version of values versus the JSON representation. From an email conversation:\r\n\r\nPlain Text\r\n---------------\r\n\r\n$ curl -H \"curl -H \"Accept: text/plain\" localhost:8888/status/cluster\r\n1 live servers, 0 dead servers, 5.0000 average load\r\n\r\n1 live servers\r\n   de1-app-mbp-2.fritz.box:62884 1280924907616\r\n       requests=0, regions=5\r\n       heapSizeMB=27\r\n       maxHeapSizeMB=995\r\n\r\n       t2,,1280917558997\r\n           stores=3\r\n           storefiless=0\r\n           storefileSizeMB=0\r\n           memstoreSizeMB=0\r\n           storefileIndexSizeMB=0\r\n       usertable,,1280917566604\r\n           stores=3\r\n           storefiless=2\r\n           storefileSizeMB=224\r\n           memstoreSizeMB=0\r\n           storefileIndexSizeMB=0\r\n       .META.,,1\r\n           stores=2\r\n           storefiless=1\r\n           storefileSizeMB=0\r\n           memstoreSizeMB=0\r\n           storefileIndexSizeMB=0\r\n       t1,,1280917554475\r\n           stores=3\r\n           storefiless=0\r\n           storefileSizeMB=0\r\n           memstoreSizeMB=0\r\n           storefileIndexSizeMB=0\r\n       \\-ROOT\\-,,0\r\n           stores=1\r\n           storefiless=1\r\n           storefileSizeMB=0\r\n           memstoreSizeMB=0\r\n           storefileIndexSizeMB=0\r\n\r\nJSON\r\n---------\r\n\r\nAnd curling the JSON yields:\r\n\r\n$ curl -H \"Accept: application/json\" localhost:8888/status/cluster\r\n{\"requests\":0,\"regions\":5,\"averageLoad\":5.0,\"DeadNodes\":[null],\"LiveNodes\":[{\"Node\":{\"startCode\":1280924907616,\"requests\":0,\"name\":\"de1-app-mbp-2.fritz.box:62884\",\"maxHeapSizeMB\":995,\"heapSizeMB\":27,\"Region\":[{\"stores\":3,\"storefiles\":0,\"storefileSizeMB\":0,\"storefileIndexSizeMB\":0,\"name\":\"dDIsLDEyODA5MTc1NTg5OTc=\",\"memstoreSizeMB\":0},{\"stores\":3,\"storefiles\":2,\"storefileSizeMB\":224,\"storefileIndexSizeMB\":0,\"name\":\"dXNlcnRhYmxlLCwxMjgwOTE3NTY2NjA0\",\"memstoreSizeMB\":0},{\"stores\":2,\"storefiles\":1,\"storefileSizeMB\":0,\"storefileIndexSizeMB\":0,\"name\":\"Lk1FVEEuLCwx\",\"memstoreSizeMB\":0},{\"stores\":3,\"storefiles\":0,\"storefileSizeMB\":0,\"storefileIndexSizeMB\":0,\"name\":\"dDEsLDEyODA5MTc1NTQ0NzU=\",\"memstoreSizeMB\":0},{\"stores\":1,\"storefiles\":1,\"storefileSizeMB\":0,\"storefileIndexSizeMB\":0,\"name\":\"LVJPT1QtLCww\",\"memstoreSizeMB\":0}]}}]}\r\n\r\n\r\nAnd another one:\r\n\r\nI have another one with .META. and \\-ROOT\\-, in my small sample setup (all local, /tmp etc.) I see this in the master UI:\r\n\r\nName\t Region Server\t Encoded Name\t Start Key\t End Key\r\n.META.,,1\t10.0.0.43:60030\t -\t\t\r\n\r\nBut running the same against Stargate I get:\r\n\r\n$ curl -H \"Accept: application/json\" http://localhost:8888/.META./regions\r\n{\"name\":\".META.\"}\r\n\r\nwhile a \"normal\" user table with a single row has\r\n\r\nName\t Region Server\t Encoded Name\t Start Key\t End Key\r\nt1,,1281111615489\t10.0.0.43:60030\t 1127696125\t\t\r\n\r\nand through Stargate:\r\n\r\n$ curl -H \"Accept: application/json\" http://localhost:8888/t1/regions\r\n{\"name\":\"t1\",\"Region\":[{\"location\":\"10.0.0.43:54988\",\"endKey\":\"\",\"startKey\":\"\",\"id\":1281111615489,\"name\":\"t1,,1281111615489\"}]}\r\n\r\nSo the internal tables are not reported right.\r\n"
    ],
    [
        "HBASE-2645",
        "HBASE-7185",
        "HLog writer can do 1-2 sync operations after lease has been recovered for split process. TestHLogSplit.testLogCannotBeWrittenOnceParsed is failing. \r\n\r\nThis test starts a thread that writes one edit to the log, syncs and counts. During this, a HLog.splitLog operation is started. splitLog recovers the log lease before reading the log, so that the original regionserver could not wake up and write after the split process started.  \r\nThe test compares the number of edits reported by the split process and by the writer thread. Writer thread (called zombie in the test) should report <=  than the splitLog (sync() might raise after the last edit gets written and the edit won't get counted by zombie thread). However it appears that the zombie counts 1-2 more edits. So it looks like it can sync without a lease.\r\n\r\nThis might be a hdfs-0.20 related issue. ",
        "Create hbase-protocol module Create an hbase-rpc module where protobuf's that can cross the wire(either to zk or from a server) will be stored.  This should allow others to create clients without relying on too much of the hbase code base."
    ],
    [
        "HBASE-1134",
        "HBASE-609",
        "OOME in HMaster when HBaseRPC is older than 0.19 When the Master receives a RPC call from any other version than 0.19, it gets:\n{code}\n2009-01-17 22:04:00,266 WARN org.apache.hadoop.ipc.HBaseServer: Out of Memory in server select\njava.lang.OutOfMemoryError: Java heap space\n        at org.apache.hadoop.hbase.ipc.HBaseRPC$Invocation.readFields(HBaseRPC.java:142)\n        at org.apache.hadoop.hbase.ipc.HBaseServer$Connection.processData(HBaseServer.java:847)\n        at org.apache.hadoop.hbase.ipc.HBaseServer$Connection.readAndProcess(HBaseServer.java:814)\n        at org.apache.hadoop.hbase.ipc.HBaseServer$Listener.doRead(HBaseServer.java:399)\n        at org.apache.hadoop.hbase.ipc.HBaseServer$Listener.run(HBaseServer.java:308)\n{code}\n\nEasy to recreate by just starting a local 0.19 HBase and using the 0.18 shell to create a table.",
        "Master doesn't see regionserver edits because of clock skew The streamy folks had a cluster where regionserver was 2 minutes in advance of the master.  On split, regionserver would update .META. with split info but scanners opened on the master wouldn't see the edits because they were being opened using current time."
    ],
    [
        "HBASE-8337",
        "HBASE-1586",
        "Investigate why disabling hadoop short circuit read is required to make recovery tests pass consistently under hadoop2 HBASE-7636 makes some TestDistributedLogSplitting pass consistently by disabling hdfs short circuit reads.  \r\nHBASE-8349 makes datanode node death recovery pass consistently by disabling hdfs short circuit reads.\r\n\r\nThis will likely require configuration modifications to fix and may have different fixes for hadoop1, hadoop2 (HDFS-2246), and hadoop3 (HDFS-347)...",
        "Bring back transactions and indexing for 0.20 Bring back transactions and indexing for 0.20. Stack suggests moving into contrib, which I'm fine with. Currently, the only sticking point I see is that we have already polluted HTableDescriptor with a list of indexSpecifications, so moving it out will require migration.."
    ],
    [
        "HBASE-2414",
        "HBASE-5027",
        "Enhance test suite to be able to specify distributed scenarios We keep finding good cases that are reasonably hard to test, yet the test suite does not encode these. \r\nFor example: \r\nHBASE-2413 Master does not respect generation stamps, may result in meta getting permanently offlined\r\nHBASE-2312 Possible data loss when RS goes into GC pause while rolling HLog\r\n\r\nI am sure there are many more such \"scenarios\" we should put into the unit tests. \r\n\r\n",
        "HConnection.create(final Connection conf) does not clone, it creates a new Configuration reading *.xmls and then does a merge. Its more expensive that it should be; its causing TestAdmin to fail after HBASE-4417  went in."
    ],
    [
        "HBASE-3583",
        "HBASE-1824",
        "Coprocessors: RegionObserver: ScannerNext and ScannerClose hooks are called when get() is invoked RegionObserver upcalls are expected to be triggered by corresponding client calls. \r\n\r\nI found that if a HTable.get() is issued, ScannerNext, and ScannerClose hooks are also invoked. \r\n\r\nHere is the reason: HRegion.get() is implemented with an internal scanner:\r\n\r\n{code}\r\n    InternalScanner scanner = null;\r\n    try {\r\n      scanner = getScanner(scan);\r\n      scanner.next(results);\r\n    } finally {\r\n      if (scanner != null)\r\n        scanner.close();\r\n    }\r\n{code}\r\n\r\nwhere scanner.next, and scanner.close() are implemented with RegionObserver hooks. \r\n\r\n",
        "[stargate] default timestamp should be LATEST_TIMESTAMP From Greg Cottman up on hbase-user@\r\n\r\n{quote}\r\nf I don't put the optional \"timestamp\" attribute in a Cell when I'm inserting data, the timestamp ends up as zero, which caused much confusion because it pre-dates the value I thought I was replacing.  I assumed that not specifying this attribute would cause the timestamp to default to the current HBase server time.  Instead I found I had to specify the timestamp as \"-1\" to get this behaviour.  Is this a bug or an intentional semantic?\r\n{quote}"
    ],
    [
        "HBASE-1979",
        "HBASE-1338",
        "MurmurHash does not yield the same results as the reference C++ implementation when size % 4 >= 2 Last rounds of MurmurHash are done in reverse order. data[length - 3], data[length - 2] and data[length - 1] in the block processing the remaining bytes should be data[len_m +2], data[len_m + 1], data[len_m].\r\n",
        "HBASE-1234 lost use of compaction.dir; we were compacting into live store subdirectory Found up on Ryan's cluster."
    ],
    [
        "HBASE-6116",
        "HBASE-867",
        "Allow parallel HDFS writes for HLogs. In HDFS-1783 I adapted Dhrubas changes to be used in Hadoop trunk.\r\nThis issue will include the necessary reflection changes to optionally enable this for the WALs in HBase.",
        "If millions of columns in a column family, hbase scanner won't come up Our Daniel has uploaded a table that has a column family with millions of columns in it.  He can get items from the table promptly specifying row and column.  Scanning is another matter.  Thread dumping I see we're stuck in the scanner constructor nexting through cells."
    ],
    [
        "HBASE-1450",
        "HBASE-93",
        "Scripts passed to hbase shell do not have shell context set up for them The run of a passed script is happening before all of the setup in hirb.rb.  Fix.",
        "[Hbase Shell] Error in Help-string of create command. - \"[BLOOMFILTER=NONE|BLOOM|COUNTING|RETOUCHED VECTOR_SIZE=n NUM_HASH=n], \"\n+ \"[BLOOMFILTER=NONE|BLOOMFILTER|COUNTING_BLOOMFILTER|RETOUCHED_BLOOMFILTER VECTOR_SIZE=n NUM_HASH=n], \""
    ],
    [
        "HBASE-6395",
        "HBASE-986",
        "TestFSSchedulerApp should be in scheduler.fair package MAPREDUCE-3451 added Fair Scheduler to MRv2\r\n\r\nTestFSSchedulerApp was added under src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair but its package was declared to be org.apache.hadoop.yarn.server.resourcemanager.scheduler",
        "Cache sockets in DFSClient Talking with Dhruba here at Apachecon, he suggested that setup of sockets is big price payed during random-read.  Stefan hacked into DFSClient an ugly patch that would allow us quickly test random-reading on top of a cache of cached sockets.  I just tested it.  I see 4X improvement.\n\nMaking this a blocker on 0.19.0.  Looks like we can hack in a real socket pool using a custom SocketFactory under DFSClient.  It'll be messy but the promised improvement is big."
    ],
    [
        "HBASE-3941",
        "HBASE-13210",
        "\"hbase version\" command line should print version info Hadoop has the handy feature where you can dump the version info. eg:\r\n{code}\r\n# hadoop version\r\nHadoop 0.20.2-cdh3u1-SNAPSHOT\r\nSubversion  -r d94813ecd0d4b3f63f4d30baa8a22a59dc76d5a8\r\nCompiled by root on Wed May 25 03:15:04 EDT 2011\r\nFrom source with checksum 72d8d076770d2afa1f16f06d31d2b58a\r\n{code}\r\n\r\nWe should do the same with hbase",
        "Procedure V2 - master Modify table master side, part of HBASE-12439\r\nstarts up the procedure executor on the master\r\nand replaces the modify table handlers with the procedure version."
    ],
    [
        "HBASE-14802",
        "HBASE-5416",
        "Replaying server crash recovery procedure after a failover causes incorrect handling of deadservers The way dead servers are processed is that a ServerCrashProcedure is launched for a server after it is added to the dead servers list. \r\nEvery time a server is added to the dead list, a counter \"numProcessing\" is incremented and it is decremented when a crash recovery procedure finishes. Since, adding a dead server and recovering it are two separate events, it can cause inconsistencies.\r\n\r\nIf a master failover occurs in the middle of the crash recovery, the numProcessing counter resets but the ServerCrashProcedure is replayed by the new master. This causes the counter to go negative and makes the master think that dead servers are still in process of recovery. \r\nThis has ramifications on the balancer that the balancer ceases to run after such a failover.",
        "Filter on one CF and if a match, then load and return full row (WAS: Improve performance of scans with some kind of filters) When the scan is performed, whole row is loaded into result list, after that filter (if exists) is applied to detect that row is needed.\r\n\r\nBut when scan is performed on several CFs and filter checks only data from the subset of these CFs, data from CFs, not checked by a filter is not needed on a filter stage. Only when we decided to include current row. And in such case we can significantly reduce amount of IO performed by a scan, by loading only values, actually checked by a filter.\r\n\r\nFor example, we have two CFs: flags and snap. Flags is quite small (bunch of megabytes) and is used to filter large entries from snap. Snap is very large (10s of GB) and it is quite costly to scan it. If we needed only rows with some flag specified, we use SingleColumnValueFilter to limit result to only small subset of region. But current implementation is loading both CFs to perform scan, when only small subset is needed.\r\n\r\nAttached patch adds one routine to Filter interface to allow filter to specify which CF is needed to it's operation. In HRegion, we separate all scanners into two groups: needed for filter and the rest (joined). When new row is considered, only needed data is loaded, filter applied, and only if filter accepts the row, rest of data is loaded. At our data, this speeds up such kind of scans 30-50 times. Also, this gives us the way to better normalize the data into separate columns by optimizing the scans performed."
    ],
    [
        "HBASE-6868",
        "HBASE-2569",
        "Skip checksum is broke; are we double-checksumming by default? The HFile contains checksums for decrease the iops, so when Hbase read HFile , that dont't need to read the checksum from meta file of HDFS.  But HLog file of Hbase don't contain the checksum, so when HBase read the HLog, that must read checksum from meta file of HDFS.  We could  add setSkipChecksum per file to hdfs or we could write checksums into WAL if this skip checksum facility is enabled ",
        "Improper error handling in face of version mismatch between the client and the server I use trunk, and every once in a while, when I upgrade my test instance of HBase, my clients end up in a seemingly endless loop when instantiating an {{HTable}} instance:\r\n{code}\r\n10/05/18 23:42:46 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 192.168.0.7:61322\r\n10/05/18 23:42:47 DEBUG client.HConnectionManager$TableServers: Root region location changed. Sleeping.\r\n10/05/18 23:42:48 DEBUG client.HConnectionManager$TableServers: Wake. Retry finding root region.\r\n{code}\r\nI'm pretty certain that the code throws an appropriate exception to complain about the version mismatch but it must be getting eaten somewhere and the code probably applies the usual retry logic instead of throwing up its hands in the air and immediately giving up, as I think it should."
    ],
    [
        "HBASE-8469",
        "HBASE-4408",
        "[hadoop2] Several tests break because of HDFS-4305 Several unit tests will break due to HDFS-4305 (which enforces a min block size) because apprently, we set our block size smaller in these tests. \r\n\r\n{code}\r\nSpecified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 1024 < 1048576\r\n  at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:1816)\r\n  at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1795)\r\n  at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:418)\r\n  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:205)\r\n  at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:44134)\r\n  at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:453)\r\n  at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1002)\r\n  at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1696)\r\n  at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1692)\r\n  at java.security.AccessController.doPrivileged(Native Method)\r\n  at javax.security.auth.Subject.doAs(Subject.java:396)\r\n  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)\r\n  at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1690)\r\n{code}\r\n\r\norg.apache.hadoop.hbase.regionserver.TestHRegion.testgetHDFSBlocksDistribution\r\norg.apache.hadoop.hbase.regionserver.TestHRegionBusyWait.testgetHDFSBlocksDistribution\r\norg.apache.hadoop.hbase.replication.TestMasterReplication.testCyclicReplication\r\norg.apache.hadoop.hbase.replication.TestMasterReplication.testSimplePutDelete\r\norg.apache.hadoop.hbase.replication.TestMultiSlaveReplication.testMultiSlaveReplication\r\norg.apache.hadoop.hbase.util.TestFSUtils.testcomputeHDFSBlocksDistribution",
        "book.xml - faq.  adding entry about 'why hbase?' and moving another entry from general to runtime Adding short entry to FAQ about \"why hbase?\"  This has also come up in the dist-list recently and I realized we actually didn't have than in the book yet.\r\n\r\nAlso, moved a FAQ entry about log-messages from the 'general' section to 'runtime'\r\n\r\n"
    ],
    [
        "HBASE-12953",
        "HBASE-485",
        "RegionServer is not functionally working with AysncRpcClient in secure mode HBase version 2.0.0\r\nDefault value for {{hbase.rpc.client.impl}} is set to AsyncRpcClient.\r\nWhen trying to install HBase with Kerberos, RegionServer is not working functionally.\r\nThe following log is logged in its log file\r\n{noformat}\r\n2015-02-02 14:59:05,407 WARN  [AsyncRpcChannel-pool1-t1] channel.DefaultChannelPipeline: An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.\r\nio.netty.channel.ChannelPipelineException: org.apache.hadoop.hbase.security.SaslClientHandler.handlerAdded() has thrown an exception; removed.\r\n\tat io.netty.channel.DefaultChannelPipeline.callHandlerAdded0(DefaultChannelPipeline.java:499)\r\n\tat io.netty.channel.DefaultChannelPipeline.callHandlerAdded(DefaultChannelPipeline.java:481)\r\n\tat io.netty.channel.DefaultChannelPipeline.addFirst0(DefaultChannelPipeline.java:114)\r\n\tat io.netty.channel.DefaultChannelPipeline.addFirst(DefaultChannelPipeline.java:97)\r\n\tat io.netty.channel.DefaultChannelPipeline.addFirst(DefaultChannelPipeline.java:235)\r\n\tat io.netty.channel.DefaultChannelPipeline.addFirst(DefaultChannelPipeline.java:214)\r\n\tat org.apache.hadoop.hbase.ipc.AsyncRpcChannel$2.operationComplete(AsyncRpcChannel.java:194)\r\n\tat org.apache.hadoop.hbase.ipc.AsyncRpcChannel$2.operationComplete(AsyncRpcChannel.java:157)\r\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:680)\r\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:603)\r\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:563)\r\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:406)\r\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:82)\r\n\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:253)\r\n\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:288)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]\r\n\tat com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212)\r\n\tat org.apache.hadoop.hbase.security.SaslClientHandler.handlerAdded(SaslClientHandler.java:154)\r\n\tat io.netty.channel.DefaultChannelPipeline.callHandlerAdded0(DefaultChannelPipeline.java:486)\r\n\t... 20 more\r\nCaused by: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)\r\n\tat sun.security.jgss.krb5.Krb5InitCredential.getInstance(Krb5InitCredential.java:147)\r\n\tat sun.security.jgss.krb5.Krb5MechFactory.getCredentialElement(Krb5MechFactory.java:121)\r\n\tat sun.security.jgss.krb5.Krb5MechFactory.getMechanismContext(Krb5MechFactory.java:187)\r\n\tat sun.security.jgss.GSSManagerImpl.getMechanismContext(GSSManagerImpl.java:223)\r\n\tat sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:212)\r\n\tat sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179)\r\n\tat com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193)\r\n{noformat}\r\n\r\nWhen set hbase.rpc.client.impl to RpcClientImpl, there seems to be no issue.",
        "Two runs of PerformanceEvaluation from HBase trunk  failed with region off-line error Two runs of the PerformanceEvaluation job on our test cluster running HBase trunk failed with region offline error.\n\nThe following is an excerpt from the failed task's log:\n{code}\n2008-03-01 19:30:42,184 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found possible location for TestTable,0066060288,999999999999999, address: 208.76.44.140:8020, regioninfo: regionname: .META.,,1, startKey: <>, endKey: <>, encodedName: 1028785192, tableDesc: {name: .META., families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}\n2008-03-01 19:30:42,186 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: HRegionInfo was null or empty in .META.\n2008-03-01 19:30:42,186 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of TestTable,0066060288,999999999999999\n2008-03-01 19:30:42,188 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found ROOT regionname: -ROOT-,,0, startKey: <>, endKey: <>, encodedName: 70236052, tableDesc: {name: -ROOT-, families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}\n2008-03-01 19:30:52,196 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found possible location for TestTable,0066060288,999999999999999, address: 208.76.44.140:8020, regioninfo: regionname: .META.,,1, startKey: <>, endKey: <>, encodedName: 1028785192, tableDesc: {name: .META., families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}\n2008-03-01 19:30:52,200 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: HRegionInfo was null or empty in .META.\n2008-03-01 19:30:52,200 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of TestTable,0066060288,999999999999999\n2008-03-01 19:30:52,203 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found ROOT regionname: -ROOT-,,0, startKey: <>, endKey: <>, encodedName: 70236052, tableDesc: {name: -ROOT-, families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}\n2008-03-01 19:31:02,219 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found possible location for TestTable,0066060288,999999999999999, address: 208.76.44.140:8020, regioninfo: regionname: .META.,,1, startKey: <>, endKey: <>, encodedName: 1028785192, tableDesc: {name: .META., families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}\n2008-03-01 19:31:02,236 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: reloading table servers because: HRegionInfo was null or empty in .META.\n2008-03-01 19:31:02,237 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of TestTable,0066060288,999999999999999\n2008-03-01 19:31:02,240 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found ROOT regionname: -ROOT-,,0, startKey: <>, endKey: <>, encodedName: 70236052, tableDesc: {name: -ROOT-, families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}\n2008-03-01 19:31:12,261 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Found possible location for TestTable,0066060288,999999999999999, address: 208.76.44.140:8020, regioninfo: regionname: .META.,,1, startKey: <>, endKey: <>, encodedName: 1028785192, tableDesc: {name: .META., families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}\n2008-03-01 19:31:12,270 WARN org.apache.hadoop.mapred.TaskTracker: Error running child\njava.lang.RuntimeException: java.lang.IllegalStateException: region offline: TestTable,0012639235,1204398750147\n\tat org.apache.hadoop.hbase.client.HTable.getRegionServerWithRetries(HTable.java:1019)\n\tat org.apache.hadoop.hbase.client.HTable.commit(HTable.java:753)\n\tat org.apache.hadoop.hbase.PerformanceEvaluation$SequentialWriteTest.testRow(PerformanceEvaluation.java:465)\n\tat org.apache.hadoop.hbase.PerformanceEvaluation$Test.test(PerformanceEvaluation.java:333)\n\tat org.apache.hadoop.hbase.PerformanceEvaluation.runOneClient(PerformanceEvaluation.java:529)\n\tat org.apache.hadoop.hbase.PerformanceEvaluation$EvaluationMapTask.map(PerformanceEvaluation.java:178)\n\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:208)\n\tat org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2071)\nCaused by: java.lang.IllegalStateException: region offline: TestTable,0012639235,1204398750147\n\tat org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:447)\n\tat org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:352)\n\tat org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:314)\n\tat org.apache.hadoop.hbase.client.HTable.getRegionLocation(HTable.java:109)\n\tat org.apache.hadoop.hbase.client.HTable$ServerCallable.instantiateServer(HTable.java:992)\n\tat org.apache.hadoop.hbase.client.HTable.getRegionServerWithRetries(HTable.java:1006)\n\t... 8 more\n{code}\n"
    ],
    [
        "HBASE-1374",
        "HBASE-5135",
        "NPE out of hbase.zookeeper.ZooKeeperWrapper.loadZooKeeperConfig java.lang.ExceptionInInitializerError\r\n        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getZooKeeperWrapper(HConnectionManager.java:792)\r\n        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getMaster(HConnectionManager.java:230)\r\n        at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:70)\r\n        at net.iridiant.content.Content.createTables(Unknown Source)\r\n        at net.iridiant.heritrix.writer.HBaseWriter.<init>(Unknown Source)\r\n        at net.iridiant.heritrix.writer.HBaseWriterPool$1.makeObject(Unknown Source)\r\n        at org.apache.commons.pool.impl.FairGenericObjectPool.borrowObject(FairGenericObjectPool.java:262)\r\n        at org.archive.io.WriterPool.borrowFile(WriterPool.java:139)\r\n        at net.iridiant.heritrix.writer.HBaseWriterProcessor.write(Unknown Source)\r\n        at net.iridiant.heritrix.writer.HBaseWriterProcessor.innerProcessResult(Unknown Source)\r\n        at org.archive.modules.Processor.process(Processor.java:123)\r\n        at org.archive.crawler.framework.ToeThread.processCrawlUri(ToeThread.java:310)\r\n        at org.archive.crawler.framework.ToeThread.run(ToeThread.java:157)\r\nCaused by: java.lang.NullPointerException\r\n        at java.util.Properties$LineReader.readLine(Properties.java:418)\r\n        at java.util.Properties.load0(Properties.java:337)\r\n        at java.util.Properties.load(Properties.java:325)\r\n        at org.apache.hadoop.hbase.zookeeper.HQuorumPeer.parseConfig(HQuorumPeer.java:93)\r\n        at org.apache.hadoop.hbase.zookeeper.HQuorumPeer.parseZooKeeperConfig(HQuorumPeer.java:79)\r\n        at org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.loadZooKeeperConfig(ZooKeeperWrapper.java:145)\r\n        at org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.<clinit>(ZooKeeperWrapper.java:58)\r\n        ... 13 more\r\n",
        "TableMapReduceUtil should be using the DistributedCache API, not the 'tmpjars' config directly. The jar adding methods of TableMapReduceUtil seem to be bypassing the DistributedCache API by plugging in the jar lists themselves to the actual property. This is not a good practice and must be avoided if possible.\r\n\r\n_Observed during HBASE-3274_."
    ],
    [
        "HBASE-14151",
        "HBASE-4091",
        "Remove the unnecessary file ProtobufUtil.java.rej which is brought in by merging hbase-11339   When merging the feature branch hbase-11339 into trunk, one unnecessary file is committed. We need to remove it.",
        "book.xml - description of block cache in arch, description of inMemory in schema creation There have been recent threads in the dist-list about how the block cache works, exactly.  Also, what does inMemory mean?\r\n\r\nFormer was added to Arch chaper RS section, and latter added to Schema creation chaper."
    ],
    [
        "HBASE-8865",
        "HBASE-1814",
        "HBase shell split command acts incorrectly with hex split keys. When I tried to do a manual region split from HBase shell, I found that split command acts incorrectly with hex split keys. \r\n\r\nHere is an example.\r\n\r\nI execute hbase(main):003:0> split 'tsdb', \"\\x00\\x00\\xC3\" .\r\n\r\nWhile I expect it to split at the 3-byte key \"\\x00\\x00\\xC3\" , it actually split at a 5-byte key \"\\x00\\x00\\xEF\\xBF\\xBD\". \r\n\r\nI test with more split keys and find some patterns:\r\n* If the all bytes in the split key represented in hexadecimal are between \"\\x00\" and \"\\x7F\" , it works as expected and split at exactly the key specified.\r\n* If there are any bytes between \"\\x80\" and \"xFF\", it works incorrectly. No matter the byte is, it is interpreted as \"\\xEF\\xBF\\xBD\". Here is another example. Specifying split key \"\\x00\\xA0\\x00\\xB0\" actually splits at \"\\x00\\xEF\\xBF\\xBD\\x00\\xEF\\xBF\\xBD\".\r\n\r\nI'm running Hbase 0.94.8, r1485407, both server-side and client-side. \r\n\r\n",
        "jgray, stack and ryan should not be allowed to ride in the same car at once ever again as per #hbase:\r\n\r\n12:22 < larsgeorge> you gueys should not be allowed in the same car - ever\r\n12:22 < larsgeorge> *guys\r\n12:22 < dj_ryan> yeah\r\n12:22 < larsgeorge> too dangerous for the project\r\n12:22 < dj_ryan> it was pretty much some of the core hbase braintrust in 1 car\r\n12:22 < rpaddock> I'd file a jira about that\r\n\r\nThe risk is clearly too great. "
    ],
    [
        "HBASE-10050",
        "HBASE-11422",
        "graceful_stop.sh syntax error When i was trying to run graceful_stop.sh i got error:\r\n{code}\r\n./graceful_stop.sh: line 59: syntax error near unexpected token `;'\r\n./graceful_stop.sh: line 59: `    --failfast) ;&'\r\n{code}\r\nAfter looking at script i notice that this lines are causing error:\r\n{code}\r\n    --failfast) ;&\r\n    -e)  failfast=true; shift;;\r\n    --debug)  ;&\r\n    -d)  debug=\"--debug\"; shift;;\r\n{code} \r\n\r\nThey sholud be changed to this:\r\n{code}\r\n --failfast | -e)  failfast=true; shift;;\r\n --debug | -d)  debug=\"--debug\"; shift;;\r\n{code}\r\n\r\nI will attach patch today. ",
        "Specification of scope is missing for certain Hadoop dependencies [~cos] reported in the mailing thread, 'HBase 0.98.x dependency problems', that specifying hadoop-two.version with value other than 2.2.0 pulls in incorrect dependencies such as:\r\n{code}\r\n[INFO] |  \\- org.apache.hadoop:hadoop-hdfs:test-jar:tests:2.2.0:compile\r\n{code}\r\nThis is due to missing specification of scope in the pom.xml files."
    ],
    [
        "HBASE-4546",
        "HBASE-3055",
        "Upgrade to ZooKeeper 3.3.2 or 3.3.3 HBase is still depending on 3.3.1.  There many critical bug fixes in 3.3.2 and two more critical fixes in 3.3.3.\r\n\r\nWe recently tripped on ZOOKEEPER-822 which was fixed in 3.3.2.",
        "Improvements to bulk assign on startup Working on the failed hbase-3019 some improvements were made to bulk assignment:\r\n\r\n1. Temporarily disabling timeout on regions in transition\r\n2. A executor service running assignments per server rather than a thread for every server (if big cluster thread-per could be OTT).\r\n\r\n"
    ],
    [
        "HBASE-12514",
        "HBASE-12305",
        "Cleanup HFileOutputFormat legacy code HFileOutputFormat methods route to their HFileOutputFormat2 counterparts.  Replace all calls to HFileOutputFormat with HFileOutputFormat2 equivalents.\r\n\r\nIn the spirit of cleanup, add @Override annotations and helper methods that do not require the use of deprecated classes such as HTable.",
        "Memstore and MemstoreScanner should work with BBs. Anoop's work of Memstore as a block would be beneficial here and in that we could ensure that Memstore also works with buffers.  This would help in easy comparison of cells from the Readers backed by buffers and the cells in the memstores (currently backed by byte[])."
    ],
    [
        "HBASE-3315",
        "HBASE-13145",
        "Add debug output for when balancer makes bad balance Balancer had assertions at end of the balanceCluster method.  These assertions trigger on occasion -- just did for me and did previously for j-d -- only there's no data to analyze when it fails.  Add logging data on balancer input and summary.",
        "TestNamespaceAuditor.testRegionMerge is flaky Dig into the log\r\nhttps://builds.apache.org/job/HBase-TRUNK/6197/artifact/hbase-server/target/surefire-reports/org.apache.hadoop.hbase.namespace.TestNamespaceAuditor-output.txt\r\nSeems a split operation which we expect to success is started before we finishing a merge and cause an infinite sleep loop.\r\n\r\nI guess the problem is here\r\n{code:title=TestNamespaceAuditor.java}\r\n    // merge the two regions\r\n    admin.mergeRegions(hris.get(0).getEncodedNameAsBytes(),\r\n      hris.get(1).getEncodedNameAsBytes(), false);\r\n    \r\n    while (admin.getTableRegions(tableTwo).size() == initialRegions) {\r\n      Thread.sleep(100);\r\n    }\r\n{code}\r\nI guess that during a merge, we can get more region count than before because we first online the new region and then offline the two old regions.\r\nSo change it to admin.getTableRegions(tableTwo).size() != initialRegions - 1 may work.\r\n\r\nAnd we can modify the while loop to use Waiter.waitFor which can provide more useful information when test failed."
    ],
    [
        "HBASE-6781",
        "HBASE-11755",
        ".archive directory should be added to HConstants.HBASE_NON_USER_TABLE_DIRS We can see the following in test output:\r\n{code}\r\n2012-09-14 00:50:43,500 DEBUG [IPC Server handler 0 on 51461] util.FSTableDescriptors(175): Exception during readTableDecriptor. Current table name = .archive\r\norg.apache.hadoop.hbase.TableInfoMissingException: No .tableinfo file under hdfs://localhost:35107/user/jenkins/hbase/.archive\r\n\tat org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptor(FSTableDescriptors.java:417)\r\n\tat org.apache.hadoop.hbase.util.FSTableDescriptors.getTableDescriptor(FSTableDescriptors.java:408)\r\n\tat org.apache.hadoop.hbase.util.FSTableDescriptors.get(FSTableDescriptors.java:170)\r\n\tat org.apache.hadoop.hbase.util.FSTableDescriptors.getAll(FSTableDescriptors.java:201)\r\n\tat org.apache.hadoop.hbase.master.HMaster.getTableDescriptors(HMaster.java:2199)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\r\n\tat java.lang.reflect.Method.invoke(Method.java:597)\r\n\tat org.apache.hadoop.hbase.ipc.ProtobufRpcEngine$Server.call(ProtobufRpcEngine.java:357)\r\n\tat org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1816)\r\n{code}\r\n.archive directory should be added to HConstants.HBASE_NON_USER_TABLE_DIRS",
        "VisibilityController returns the wrong value for preBalanceSwitch() VisibilityController returns false instead of the newValue for the preBalanceSwitch() call.\r\n\r\nVisibilityController extends both RegionObserver and MasterObserver, unfortunately only 1 of the two can use the Base implementation. in this case the BaseRegionObserver is used and all most of the MasterObserver methods are a noop. Any idea on how to avoid reimplementing all the  interface methods as noop, and avoid problems like the preBalanceSwitch()?"
    ],
    [
        "HBASE-12845",
        "HBASE-1739",
        "ByteBufferOutputStream should grow as direct buffer if the initial buffer is also direct BB Currently ByteBufferOutputStream while trying to expand in checkSizeAndGrow(), allocates the new buffer onheap though the existing buffer is offheap",
        "hbase-1683 broke splitting; only split three logs no matter what N was. There's a hard-coding in HLog#splitLog that presumes we always read in batches of ten logs:\r\n\r\n{code}\r\nIndex: src/java/org/apache/hadoop/hbase/regionserver/HLog.java\r\n===================================================================\r\n--- src/java/org/apache/hadoop/hbase/regionserver/HLog.java     (revision 799653)\r\n+++ src/java/org/apache/hadoop/hbase/regionserver/HLog.java     (working copy)\r\n@@ -860,7 +860,7 @@\r\n         // Stop at logfiles.length when it's the last step\r\n         int endIndex = step == maxSteps - 1? logfiles.length: \r\n           step * concurrentLogReads + concurrentLogReads;\r\n-        for (int i = (step * 10); i < endIndex; i++) {\r\n+        for (int i = (step * concurrentLogReads); i < endIndex; i++) {\r\n           // Check for possibly empty file. With appends, currently Hadoop \r\n           // reports a zero length even if the file has been sync'd. Revisit if\r\n           // HADOOP-4751 is committed.\r\n{code}\r\n\r\nWhen I changed it so we default to reading 3 files at a time rather than 10 over in hbase-1683, the hard-coding made it so we didn't read all logs."
    ],
    [
        "HBASE-14335",
        "HBASE-12581",
        "TestAssignmentManagerOnCluster#testSSHWhenDisablingTableRegionsInOpeningOrPendingOpenState occasionally timing out during cleanup TestAssignmentManagerOnCluster#testSSHWhenDisablingTableRegionsInOpeningOrPendingOpenState is occasionally timing out when cleaning up after a test. Depends on environment. Given the right timing we get a timeout. One one test host, fails with 7u79. On another, passes with 7u79, fails with 8u45.\r\n\r\n{noformat}\r\nRunning org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster\r\nTests run: 17, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 85.924 sec <<< \r\nFAILURE! - in org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster\r\ntestSSHWhenDisablingTableRegionsInOpeningOrPendingOpenState(org.apache.hadoop.hb\r\nase.master.TestAssignmentManagerOnCluster)  Time elapsed: 60.036 sec  <<< ERROR!\r\njava.lang.Exception: test timed out after 60000 milliseconds\r\n        at java.lang.Thread.sleep(Native Method)\r\n        at org.apache.hadoop.hbase.client.HBaseAdmin.deleteTable(HBaseAdmin.java\r\n:724)\r\n        at org.apache.hadoop.hbase.HBaseTestingUtility.deleteTable(HBaseTestingU\r\ntility.java:1581)\r\n        at org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.testSSH\r\nWhenDisablingTableRegionsInOpeningOrPendingOpenState(TestAssignmentManagerOnClus\r\nter.java:676)\r\n{noformat}",
        "TestCellACLWithMultipleVersions failing since task 5 HBASE-12404 (HBASE-12404 addendum) TestCellACLWithMultipleVersions failed after HBASE-12404 went in (though it passed twice on hadoopqa!).  Fails locally too.  Here, make a Connection when we go to check perms.  That seems to fix it. Going to commit since patch is just more of hbase-12404... this is in essence and addendum."
    ],
    [
        "HBASE-7543",
        "HBASE-8014",
        "TestSnapshotDescriptionUtils#testValidateGlobalSnapshotDescriptor fails   testValidateGlobalSnapshotDescriptor(org.apache.hadoop.hbase.snapshot.TestSnapshotDescriptionUtils): Message missing required fields: name\r\n",
        "Backport HBASE-6915 to 0.94. JDK 1.7 changed some data size. Goal of this JIRA is to backport HBASE-6915 to 0.94"
    ],
    [
        "HBASE-10443",
        "HBASE-11593",
        "IndexOutOfBoundExceptions when processing compressed tags in HFile As HBASE-10438 got closed, we still need to fix the Index out of bound exception that occurs.  If we have a proper fix will fix this, if the bug was a false alarm would close this. ",
        "TestCacheConfig failing consistently in precommit builds As stated in description"
    ],
    [
        "HBASE-12115",
        "HBASE-8420",
        "Fix NumberFormat Exception in TableInputFormatBase. DNS.reverseDns doesn't work well with IPv6 addresses. This patch is to fix that.",
        "Port  HBASE-6874  Implement prefetching for scanners from 0.89-fb This should help scanner performance.  We should have it in trunk."
    ],
    [
        "HBASE-8784",
        "HBASE-12674",
        "Wildcard/Range/Partition Delete Support We often see use-cases where users, for example with timeseries data, would like to do deletes of large ranges of data, basically like a delete of a partition as supported by RDBMSs. We should support regular expressions or range expressions for the matches (supporting binary keys obviously).\r\n\r\nThe idea is to store the deletes not with the data, but the meta data. When we read files we read the larger deletes first, and then the inline ones. Of course, this should be reserved for few but very data intensive deletes. This reduces the number of deletes to write to one, instead of many (often thousands, if not millions). This is different from the BulkDeleteEndpoint introduced in HBASE-6942. It should support similar Scan based selectiveness. \r\n\r\nThe new range deletes will mask out all the matching data and handled otherwise like other deletes, for example being dropped during major compactions, once all masked data has been dropped too.\r\n\r\nTo be discussed is how and where we store the delete entry in practice, since meta data might not be wanted. But it seems like a reasonable choice. The DeleteTracker can handle the delete the same with additional checks for wildcards/ranges. If the deletes are not used, no critical path is affected, therefore not causing any additional latencies or other regressions.",
        "Add permission check to getNamespaceDescriptor() Add permission check to getNamespaceDescriptor()"
    ],
    [
        "HBASE-14592",
        "HBASE-3139",
        "BatchRestartRsAction always restarts 0 RS when running SlowDeterministicMonkey When running ITBLL, observed below log and found the ratio of batch restarting is always zero:\r\n{noformat}\r\n15/10/12 17:05:37 INFO actions.Action: Performing action: Batch restarting 0% of region servers\r\n{noformat}\r\n\r\nChecking code, found batchRestartRSRatio never got initialized in SlowDeterministicMonkeyFactory, and current ITBLL never check the case of batch RS restarting in actual.",
        "Server shutdown processor stuck because meta not online Playing with rolling restart I see that the server hosting root and meta can go down close to each other.  In below, note how we are processing server hosting -ROOT- and part of its processing involves reading .META. content to see what servers it was carrying.  Well, note that .META. is offline at time (our verification attempt failed because server had just been shutdown and verification got ConnectException).  So we pause the server shutdown processing till .META. comes back online -- only it never does.\r\n\r\n{code}\r\n2010-10-21 07:32:23,931 INFO org.apache.hadoop.hbase.catalog.RootLocationEditor: Unsetting ROOT region location in ZooKeeper\r\n2010-10-21 07:32:23,953 INFO org.apache.hadoop.hbase.master.handler.ServerShutdownHandler: Splitting logs for sv2borg182,60020,1287645693959                                                                                       2010-10-21 07:32:23,994 INFO org.apache.hadoop.hbase.catalog.RootLocationEditor: Unsetting ROOT region location in ZooKeeper\r\n2010-10-21 07:32:24,020 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12bcd5b344b0115 Creating (or updating) unassigned node for 70236052 with OFFLINE state                                                    2010-10-21 07:32:24,045 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: No previous transition plan for -ROOT-,,0.70236052 so generated a random one; hri=-ROOT-,,0.70236052, src=, dest=sv2borg181,60020,1287646329081; 8 (online=8, exclude=null) available servers                                                                                                                                                                                         2010-10-21 07:32:24,045 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Assigning region -ROOT-,,0.70236052 to sv2borg181,60020,1287646329081                                                                              2010-10-21 07:32:24,048 INFO org.apache.hadoop.hbase.catalog.CatalogTracker: Failed verification of .META.,,1; java.net.ConnectException: Connection refused\r\n2010-10-21 07:32:24,048 INFO org.apache.hadoop.hbase.catalog.CatalogTracker: Current cached META location is not valid, resetting\r\n2010-10-21 07:32:24,079 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=sv2borg181,60020,1287646329081, region=70236052/-ROOT-                                            2010-10-21 07:32:24,162 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENING, server=sv2borg181,60020,1287646329081, region=70236052/-ROOT-\r\n2010-10-21 07:32:24,212 DEBUG org.apache.hadoop.hbase.master.AssignmentManager: Handling transition=RS_ZK_REGION_OPENED, server=sv2borg181,60020,1287646329081, region=70236052/-ROOT-                                             2010-10-21 07:32:24,212 DEBUG org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Handling OPENED event for 70236052; deleting unassigned node                                                                             2010-10-21 07:32:24,212 DEBUG org.apache.hadoop.hbase.zookeeper.ZKAssign: master:60000-0x12bcd5b344b0115 Deleting existing unassigned node for 70236052 that is in expected state RS_ZK_REGION_OPENED                              2010-10-21 07:32:24,238 DEBUG org.apache.hadoop.hbase.master.handler.OpenedRegionHandler: Opened region -ROOT-,,0.70236052                                                                                                         2010-10-21 07:32:27,902 INFO org.apache.hadoop.hbase.master.ServerManager: Registering server=sv2borg183,60020,1287646347597, regionCount=0, userLoad=false                                                                        2010-10-21 07:32:30,523 INFO org.apache.hadoop.hbase.zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [sv2borg184,60020,1287645693960]                                                    2010-10-21 07:32:30,523 DEBUG org.apache.hadoop.hbase.master.ServerManager: Added=sv2borg184,60020,1287645693960 to dead servers, submitted shutdown handler to be executed                                                        2010-10-21 07:32:36,254 INFO org.apache.hadoop.hbase.master.ServerManager: Registering server=sv2borg184,60020,1287646355951, regionCount=0, userLoad=false                                                                        2010-10-21 07:32:39,567 INFO org.apache.hadoop.hbase.zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [sv2borg185,60020,1287645693959]                                                    2010-10-21 07:32:39,567 DEBUG org.apache.hadoop.hbase.master.ServerManager: Added=sv2borg185,60020,1287645693959 to dead servers, submitted shutdown handler to be executed                                                        2010-10-21 07:32:45,614 INFO org.apache.hadoop.hbase.master.ServerManager: Registering server=sv2borg185,60020,1287646365304, regionCount=0, userLoad=false                                                                        2010-10-21 07:32:48,652 INFO org.apache.hadoop.hbase.zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [sv2borg186,60020,1287645693962]                                                    2010-10-21 07:32:48,652 DEBUG org.apache.hadoop.hbase.master.ServerManager: Added=sv2borg186,60020,1287645693962 to dead servers, submitted shutdown handler to be executed                                                        2010-10-21 07:32:50,097 INFO org.apache.hadoop.hbase.master.ServerManager: regionservers=8, averageload=93.38, deadservers=[sv2borg185,60020,1287645693959, sv2borg183,60020,1287645693959, sv2borg182,60020,1287645693959,        sv2borg184,60020,1287645693960, sv2borg186,60020,1287645693962]\r\n....\r\n{code}\r\n\r\nWe're supposed to have a thread of 5 executors to handle server shutdowns.  I see an executor stuck waiting on .META. but I dont see any others running.  Odd.  Trying to figure why executors are 1 only.\r\n\r\n{code}\r\n\"MASTER_SERVER_OPERATIONS-sv2borg180:60000-1\" daemon prio=10 tid=0x0000000041dc7000 nid=0x50a4 in Object.wait() [0x00007f285d537000]\r\n   java.lang.Thread.State: TIMED_WAITING (on object monitor)\r\n    at java.lang.Object.wait(Native Method)\r\n    at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMeta(CatalogTracker.java:324)\r\n    - locked <0x00007f286d150ce8> (a java.util.concurrent.atomic.AtomicBoolean)\r\n    at org.apache.hadoop.hbase.catalog.CatalogTracker.waitForMetaServerConnectionDefault(CatalogTracker.java:359)\r\n    at org.apache.hadoop.hbase.catalog.MetaReader.getServerUserRegions(MetaReader.java:487)\r\n    at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:115)\r\n    at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:150)\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\r\n    at java.lang.Thread.run(Thread.java:619)\r\n{code}"
    ],
    [
        "HBASE-9550",
        "HBASE-9786",
        "IntegrationTestBigLinkedList used to be able to run on pseudo-distributed clusters IntegrationTestBigLinkedList was able to run on clusters with 1 node (in single node deployments). We should bring that. ",
        "[hbck]: hbck -metaonly incorrectly reports inconsistent regions after HBASE-9698 fix In my testing, I found that this call began to fail:\r\n{code}sudo -u hbase hbase hbck -metaonly\r\n{code}\r\n\r\nThe checking after which it began to fail is:  after this checkin: https://github.com/apache/hbase/commit/818749ff9f261aac4206054d331189e92290b408\r\n\r\nThe full output is below. The issue seems the patch does not include -metaOnly\r\n\r\nTesting done:\r\nI build 0.96 up to commit a6f208d91efff207860b049eb8466a069f0c71a9 and the test passes.\r\n\r\nThe output:\r\n{code}\r\n$ hbase org.apache.hadoop.hbase.PerformanceEvaluation --rows=10000 sequentialWrite 1\r\n$ hbase hbck -metaonly\r\n...\r\n2013-10-16 23:52:24,075 DEBUG [main] util.HBaseFsck: There are 1 region info entries\r\nERROR: There is a hole in the region chain between  and .  You need to create a new .regioninfo and region dir in hdfs to plug the hole.\r\nERROR: Found inconsistency in table TestTable\r\nERROR: There is a hole in the region chain between  and .  You need to create a new .regioninfo and region dir in hdfs to plug the hole.\r\nERROR: Found inconsistency in table hbase:namespace\r\n2013-10-16 23:52:24,182 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hbase Fsck\r\n2013-10-16 23:52:24,183 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=hbase Fsck connecting to ZooKeeper ensemble=localhost:2181\r\n2013-10-16 23:52:24,183 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\r\n2013-10-16 23:52:24,184 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session\r\n2013-10-16 23:52:24,188 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x141c377e423000d, negotiated timeout = 40000\r\nSummary:\r\n  TestTable is okay.\r\n    Number of regions: 0\r\n    Deployed on:\r\n  hbase:meta is okay.\r\n    Number of regions: 1\r\n    Deployed on:  localhost,49217,1381963918103\r\n  hbase:namespace is okay.\r\n    Number of regions: 0\r\n    Deployed on:\r\n2 inconsistencies detected.\r\nStatus: INCONSISTENT\r\n{code}"
    ],
    [
        "HBASE-11658",
        "HBASE-12003",
        "Piped commands to hbase shell should return non-zero if shell command failed. See HBASE-11655.  We would like the shell to return non-zero when a command that has been piped to it fails in \"scripting mode\".  This could be due to invalid commands or commands issued with invalid arguments.\r\n\r\nThis would lower the barrier to entry for hbase admins so they could effectively script some operations.",
        "Fix SecureBulkLoadEndpoint class javadoc formatting Noticed while reviewing security docs. We link off to the javadoc on said class from the book. Trivial fix."
    ],
    [
        "HBASE-6102",
        "HBASE-13185",
        "API and shell usability improvements ",
        "Document hbase.regionserver.thrift.framed.max_frame_size_in_mb more clearly Current document does not make sense how much is it going to allocate for {{hbase.regionserver.thrift.framed.max_frame_size_in_mb}}:\r\n\r\nhttp://hbase.apache.org/book.html#hbase.regionserver.thrift.framed.max_frame_size_in_mb\r\n\r\nIt is 2MB by default per the code, so that it would be fine to document this:\r\nhttps://github.com/apache/hbase/blob/master/hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java#L450-L451"
    ],
    [
        "HBASE-11289",
        "HBASE-3733",
        "Speedup balance ",
        "MemStoreFlusher.flushOneForGlobalPressure() shouldn't be using TreeSet for HRegion v-himanshu found that since HRegion doesn't implement Comparable, it cannot be placed in TreeSet."
    ],
    [
        "HBASE-655",
        "HBASE-13795",
        "need programmatic way to add column family: need programmatic way to enable/disable table From HADOOP-2292:\n\n> What you might do is open a HTable on the META region (HConstants.META_TABLE_NAME) and scan HConstants.COL_REGIONINFO_ARRAY which will give you back HRegionInfo objects (as bytes).\n> Find the table in question by comparing your table name to regionInfo.getTableDesc().getName()\n> If adding or deleting columns, check regionInfo.getTableDesc().hasFamily()\n> If changing table on/off line check regionInfo.isOffline()\n> If any of the regions don't meet the criteria, close the scanner, sleep and rescan.\n\nThis is a bit too complicated for me.  If you won't make enableTable/disableTable synchronous, we should at least have a HTable.isTableDisabled method.",
        "Offline regions hard to find, provide highlighting/state info {{close_region}} removes region from {{rs-status}} page, but does not increase count in {{master-status}} page. {{table.jsp}} shows all regions but no indication of their state. In 0.92 we had highlighting of offline regions (red background). We should do the same, and maybe also add a column that states the region status.\r\n\r\nNote that using {{close_region}} is hackery, but a region could be offline for other reasons too! \r\n\r\nI also suggest adding some (maybe time delayed) check into the master to detect unassigned regions and show them properly in the table with metrics for each user table."
    ],
    [
        "HBASE-10734",
        "HBASE-8339",
        "Fix RegionStates.getRegionAssignments to not add duplicate regions RegionStates.getRegionAssignments(Collection<HRI>) erroneously adds the default replica twice to the value list in the returned map.",
        "Make sure the StochasticLoadBalancer doesn't run a cost function when not needed The cost multiplier of a cost function could be 0.  If that is the case there's no need to compute that stat's cost each time."
    ],
    [
        "HBASE-7080",
        "HBASE-7665",
        "TestHFileOutputFormat.testColumnFamilyCompression failing due to UnsatisfiedLinkError Due to HADOOP-8756, this test fails\r\n\r\n{noformat}\r\njava.lang.UnsatisfiedLinkError: org.apache.hadoop.util.NativeCodeLoader.buildSupportsSnappy()Z\r\n\tat org.apache.hadoop.util.NativeCodeLoader.buildSupportsSnappy(Native Method)\r\n\tat org.apache.hadoop.io.compress.SnappyCodec.checkNativeCodeLoaded(SnappyCodec.java:62)\r\n\tat org.apache.hadoop.io.compress.SnappyCodec.getCompressorType(SnappyCodec.java:127)\r\n\tat org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:104)\r\n\tat org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:118)\r\n\tat org.apache.hadoop.hbase.io.hfile.Compression$Algorithm.getCompressor(Compression.java:236)\r\n\tat org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.getSupportedCompressionAlgorithms(TestHFileOutputFormat.java:649)\r\n\tat org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.testColumnFamilyCompression(TestHFileOutputFormat.java:571)\r\n{noformat}",
        "retry time sequence usage in HConnectionManager has off-by-one error  Array of retries starts with element #0, but we never pass 0 into ConnectionUtils::getPauseTime - curNumRetries is 1 or higher."
    ],
    [
        "HBASE-13524",
        "HBASE-2896",
        "TestReplicationAdmin fails on JDK 1.8 {code}\r\n-------------------------------------------------------\r\n T E S T S\r\n-------------------------------------------------------\r\nJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=256m; support was removed in 8.0\r\nRunning org.apache.hadoop.hbase.client.replication.TestReplicationAdmin\r\nTests run: 5, Failures: 1, Errors: 1, Skipped: 0, Time elapsed: 2.419 sec <<< FAILURE! - in org.apache.hadoop.hbase.client.replication.TestReplicationAdmin\r\ntestAppendPeerTableCFs(org.apache.hadoop.hbase.client.replication.TestReplicationAdmin)  Time elapsed: 0.037 sec  <<< FAILURE!\r\norg.junit.ComparisonFailure: expected:<t[2;t1]> but was:<t[1;t2]>\r\n\tat org.junit.Assert.assertEquals(Assert.java:115)\r\n\tat org.junit.Assert.assertEquals(Assert.java:144)\r\n\tat org.apache.hadoop.hbase.client.replication.TestReplicationAdmin.testAppendPeerTableCFs(TestReplicationAdmin.java:170)\r\n\r\ntestEnableDisable(org.apache.hadoop.hbase.client.replication.TestReplicationAdmin)  Time elapsed: 0.031 sec  <<< ERROR!\r\njava.lang.IllegalArgumentException: Cannot add a peer with id=1 because that id already exists.\r\n\tat org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.addPeer(ReplicationPeersZKImpl.java:112)\r\n\tat org.apache.hadoop.hbase.client.replication.ReplicationAdmin.addPeer(ReplicationAdmin.java:202)\r\n\tat org.apache.hadoop.hbase.client.replication.ReplicationAdmin.addPeer(ReplicationAdmin.java:181)\r\n\tat org.apache.hadoop.hbase.client.replication.TestReplicationAdmin.testEnableDisable(TestReplicationAdmin.java:115)\r\n\r\n{code}",
        "Retain assignment information between cluster shutdown/startup Over in HBASE-57 we want to consider block locations for region assignment.  This is most important during cluster startup where you currently lose all locality because regions are assignment randomly.\r\n\r\nThis jira is about a shot-term solution to the cluster startup problem by retaining assignment information after a cluster shutdown and using it on the next cluster startup."
    ],
    [
        "HBASE-15158",
        "HBASE-12371",
        "Change order in which we do write pipeline operations; do all under row locks! Change how we do our write pipeline. I want to do all write pipeline ops under row lock so I lean on this fact fixing performance regression in check-and-set type operations like increment, append, and checkAnd* (see sibling issue HBASE-15082).\r\n\r\nTo be specific, we write like this now:\r\n\r\n{code}\r\n# take rowlock\r\n# start mvcc\r\n# append to WAL\r\n# add to memstore\r\n# let go of rowlock\r\n# sync WAL\r\n# in case of error: rollback memstore\r\n{code}\r\n\r\nInstead, write like this:\r\n\r\n{code}\r\n# take rowlock\r\n# start mvcc\r\n# append to WAL\r\n# sync WAL\r\n# add to memstore\r\n# let go of rowlock\r\n\r\n... no need to do rollback.\r\n{code}\r\n\r\nThe old ordering was put in place because it got better performance in a time when WAL was different and before row locks were read/write (HBASE-12751).\r\n\r\nTesting in branch-1 shows that a reordering and skipping mvcc waits gets us back to the performance we had before we unified mvcc and sequenceid (HBASE-8763). Tests in HBASE-15046 show that at the macro level using our usual perf tools, reordering pipeline seems to cause no slowdown (see HBASE-15046). A rough compare of increments with reordered write pipeline seems to have us getting back a bunch of our performance (see tail of https://issues.apache.org/jira/browse/HBASE-15082?focusedCommentId=15111703&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15111703 and subsequent comment).",
        "Backport IT improvements to 0.98 Umbrella for backports of integration test improvements including and since HBASE-10572 to 0.98. "
    ],
    [
        "HBASE-2592",
        "HBASE-12573",
        "Race between log splitting and log archiving/deleting I ran into an issue with my replication multi-cluster unit test where a region server was timed out (GC-style) but was still able to finish archiving an old log just after the master did a list on its directory. Log will be attached in a moment.",
        "Backport HBASE-10591 Sanity check table configuration in createTable In parent jira, it seems that we will be better off backporting HBASE-10591. "
    ],
    [
        "HBASE-4194",
        "HBASE-10295",
        "RegionSplitter: Split on under-loaded region servers first When running RegionSplitter, our app devs noticed that they were getting a lot of NSREs.  This is caused by 2 factors: \r\n\r\n1. the split itself will cause an NSRE \r\n2. any load balancing will cause one.  \r\n\r\nThe former cannot be helped.  We can more tightly control load balancing though.  Instead of doing a name-sorted round-robin split across RS in the tier, we could sort the RS's by region count.  That way, we only split an RS with 10 regions after there are no more RS with 9 regions.  This will prevent the load balancing slop from kicking in and will fix the problem where restarting RegionSplitter always starts splitting at RS #1.\r\n",
        "Refactor the replication  implementation to eliminate permanent zk node Though this is a broader and bigger change, it original motivation derives from HBASE-8751: the newly introduced per-peer tableCFs attribute should be treated the same way as the peer-state, which is a permanent sub-node under peer node but using permanent zk node is deemed as an incorrect practice. So let's refactor to eliminate the permanent zk node. And the HBASE-8751 can then align its newly introduced per-peer tableCFs attribute with this *correct* implementation theme."
    ],
    [
        "HBASE-1628",
        "HBASE-13412",
        "Split hbase-dev mailing list into hbase-{dev,issues} Hadoop did a split similar to this recently. I think splitting the mailing lists will make things much easier to manage for our developers.",
        "Region split decisions should have jitter Whenever a region splits it causes lots of IO (compactions are queued for a while). Because of this it's important to make sure that well distributed tables don't have all of their regions split at exactly the same time.\r\n\r\nThis is basically the same as our compaction jitter."
    ],
    [
        "HBASE-7581",
        "HBASE-6379",
        "TestAccessController depends on the execution order ",
        "[0.90 branch] Backport HBASE-6334 to 0.90 See HBASE-6334 for details.\r\n\r\nThe issue is that HBASE-6334 detects both HBASE-4195 (which should be backported to 0.90 -- I'll file another JIRA for that) and HBASE-2856 (which is a known issue in 0.90 that won't be fixed because it requires a change to the HFile format).  So in 0.90, we need a way to only catch HBASE-4195 failures and ignore HBASE-2856 failures.\r\n\r\nLuckily, HBASE-4195 only occurs *within* a column family, while HBASE-2856 occurs *between* column families, so we just need to add a little to the backport to differentiate."
    ],
    [
        "HBASE-76",
        "HBASE-1534",
        "Purge servers of Text Chatting with Jim while looking at profiler outputs, we should make an effort at purging the servers of the Text type so HRegionServer doesn't ever have to deal in Characters and the concomitant encode/decode to UTF-8.  Toward this end, we'd make changes like moving HStoreKey to have four rather than 3 data members: column family, column family qualifier, row + timestamp done as a basic Writable -- ImmutableBytesWritable? -- and a long rather than a Text column, Text row and a timestamp long.  This would save on our having to do the relatively expensive 'find' of the column family separator inside in extractFamily (>10% of CPU scanning).  Chatting about it, we could effect the change without change in the public client API; clients could continue to take Text type for row and column and then client-side, the convertion to HStoreKey could be done before crossing the wire to the server.\n\n ",
        "Got ZooKeeper event, state: Disconnected on HRS and then NPE on reinit We got disconnect from zk but then when we tried to reinitialize ourselves, got a NPE.  See below.\r\n\r\n{code}\r\n2009-06-17 11:58:55,102 [Thread-16] INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Starting shutdown thread. \r\n2009-06-17 11:58:55,102 [Thread-16] INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Shutdown thread complete\r\n2009-06-17 11:58:55,102 [main-EventThread] INFO org.apache.hadoop.hbase.ipc.HBaseRpcMetrics: Initializing RPC Metrics with hostName=HRegionServer, port=60021\r\n2009-06-17 11:58:55,103 [main-EventThread] INFO org.apache.hadoop.hbase.regionserver.MemcacheFlusher: globalMemcacheLimit=556.7m, globalMemcacheLimitLowMark=347.9m, maxHeap=1.4g\r\n2009-06-17 11:58:55,103 [main-EventThread] INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Runs every 10000000ms\r\n2009-06-17 11:58:55,148 [regionserver/0:0:0:0:0:0:0:0:60021] ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: Failed init\r\njava.lang.NullPointerException\r\n    at org.apache.hadoop.hbase.regionserver.HRegionServer.init(HRegionServer.java:713)\r\n    at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:431)\r\n    at java.lang.Thread.run(Thread.java:619)\r\n2009-06-17 11:58:55,153 [regionserver/0:0:0:0:0:0:0:0:60021] FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: Unhandled exception. Aborting...\r\njava.io.IOException: Region server startup failed\r\n    at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:832)\r\n    at org.apache.hadoop.hbase.regionserver.HRegionServer.init(HRegionServer.java:751)\r\n    at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:431)\r\n    at java.lang.Thread.run(Thread.java:619)\r\nCaused by: java.lang.NullPointerException\r\n    at org.apache.hadoop.hbase.regionserver.HRegionServer.init(HRegionServer.java:713)\r\n    ... 2 more   \r\n{code}"
    ],
    [
        "HBASE-10411",
        "HBASE-7762",
        "[Book] Add a kerberos 'request is a replay (34)' issue at troubleshooting section For kerberos 'request is a replay (34)' issue (HBASE-10379), adding it to the troubleshooting section in HBase book",
        "HBase version mismatch between package-info and hbase-defaults.xml When hbase is used to store external table in conjunction with hive, the create table in hive fails with the following error:\r\n\r\n{code}\r\nFailed with exception java.lang.RuntimeException: hbase-default.xml file seems to be for and old version of HBase (0.94.2), this version is 0.9\r\n4.5.5.1302010003\r\n{code}\r\n\r\nLooking at the classpath I don't see multiple version of hbase jar. Not sure where the 0.94.2 is coming from. It works fine if _hbase.defaults.for.version.skip_ is set to _true_."
    ],
    [
        "HBASE-4201",
        "HBASE-13588",
        "Fix delayed RPC crash Delayed RPC crashes if return value is not delayed and endDelay is called before the actual function returns a value.",
        "ExportSnapshot should checksum data transferred We sent quite a bit of data using ExportSnapshot and noticed some corruption.  We use checksums to verify if we have transferred a particular file but never do any verification after the file has been transferred.  I propose that we do a checksum upon completing file transfer and if the checksums do not match up, I propose we fail by throwing an IOException."
    ],
    [
        "HBASE-1999",
        "HBASE-4657",
        "When HTable goes away, close zk session in shutdown hook or something... Currently, while there is a close on HTable, it does not let go of the zk session.. it does not call close... because the session is shared by all HTables in the VM.  Add a shutdown hook that will close zk on the way out.   Otherwise it makes for session timeouts in zk server logs.",
        "Improve the efficiency of our MR jobs with a few configurations This is a low hanging fruit, some of our MR jobs like RowCounter and CopyTable don't even setCacheBlocks on the scan object which out of the box completely screws up a running system. Another thing would be to disable speculative execution."
    ],
    [
        "HBASE-1071",
        "HBASE-4706",
        "Set index interval at flush time based off count of keys and key attributes From Andrew Purtell note up on list:\n\n\"Later, maybe it would make sense to dynamically set the index\ninterval based on the distribution of cell sizes in the \nmapfile at some future time, according to some parameterized\nformula that could be adjusted with config variable(s). This\ncould be done during compaction. Would make sense to also\nconsider the distribution of key lengths. Or there could be\nother similar tricks implemented to keep index sizes down. \"",
        "HBASE-4120 Create shell or portal tool for user to manage priority and group Add a tool for user to manage the functions provided by HBase-4120"
    ],
    [
        "HBASE-10639",
        "HBASE-5484",
        "Unload script displays wrong counts (off by one) when unloading regions  Upon running an unload command, such as:\r\nhbase org.jruby.Main /usr/lib/hbase/bin/region_mover.rb unload `hostname`, the region counter is indexed at 0 and hence, when the regions are being moved, regions are being counted from 0 instead of 1.",
        "Spelling mistake in error message in HMasterCommandLine If hadoop-zookeeper-server is installed and started, starting hbase-master in standalone mode will display this error message which has some typos.\r\n\r\n$ sudo /etc/init.d/hadoop-hbase-master start\r\nStarting Hadoop HBase master daemon: starting master, logging to /usr/lib/hbase/logs/hbase-hbase-master/cloudera-vm.out\r\nCouldnt start ZK at requested address of 2181, instead got: 2182.  Aborting. Why? Because clients (eg shell) wont be able to find this ZK quorum\r\nhbase-master."
    ],
    [
        "HBASE-2977",
        "HBASE-2389",
        "Refactor HMaster command line tool into a new class The whole main() thing inside of HMaster is a bit messy. I'd like to refactor it to a new class.",
        "HTable - delete / put unnecessary sync.  HTable is not thread-safe , but some of the methods seem to have a synchronized block  (put/delete) etc. \r\n\r\nIt might as well be better to remove them altogether. \r\n"
    ],
    [
        "HBASE-12961",
        "HBASE-9398",
        "Negative values in read and write region server metrics  HMaster web page ui, shows the read/write request per region server. They are currently displayed by using 32 bit integers. Hence, if the servers are up for a long time the values can be shown as negative.",
        "Get HBASE-9190 to branck 0.95 On HBASE-9190, it says it is fixed in 0.95.2.  However, the issue is still there. Found out it is not checked into 0.95 branch.  Let me check it into 0.95."
    ],
    [
        "HBASE-3183",
        "HBASE-12323",
        "Commits of HBASE-3102 and HBASE-3160 broke TestHeapSize Both JIRAs added class members to Store.",
        "Provide programatic access to master webUI port Currently there's no way to get a dynamically assigned webUI port for the master. For instance, I'd like to access jmx metrics from an integration test; currently there's no easy way to grab this info.\r\n\r\nI propose tracking master's ServerInfo instead of ServerName in ZK. Other ideas?"
    ],
    [
        "HBASE-3073",
        "HBASE-12895",
        "New APIs for Result, faster implementation for some calls Our existing API for Result hasn't been given much love in the last year.  In the mean time, inefficiencies in the existing implementation have come to light, causing issues with benchmarks.  Furthermore, some people are finding the API both difficult to use as well as not useful enough (See: HBASE-1937).\r\n\r\nI propose the following new APIs:\r\npublic List<KeyValue> getColumn(byte [] family, byte [] qualifier);\r\npublic KeyValue getColumnLatest(byte [] family, byte [] qualifier);\r\n\r\nThe implementation of these use a binary search on the underlying kvs array (which is sorted).  I also have new implementations for\r\npublic boolean containsColumn(byte [] family, byte [] qualifier);\r\npublic byte [] getValue(byte [] family, byte [] qualifier);\r\n\r\nWhich in the small case run faster, but in the big case seem to run a bit slower.  That is if you call getValue() 10 times for a Result it will be faster with the new implementation, but if you call getValue() 100 times for the same Result it is faster using the old implementation.  My tests indicated about 10% slower on 'getValue' 100x with an overall 1000x iteration on 1000 different Result objects.  Considering most people use getValue() to retrieve named columns and iteration when the qualifier list is unknown I think this is a reasonable trade off.\r\n\r\nAlong with the new API, there is a recommendation to use raw() to get the list of KeyValue objects for iteration.  This increases the visibility of KeyValue, and also is much faster to iterate (4.9 times on my mini benchmark, 100 columns per Result, redone 1000 times on different Result objects).\r\n\r\nGiven my recent major speed boost by changing YCSB to use the raw() interface, I think that this is a must have for 0.90.  ",
        "Introduce BufferedTable Over on HBASE-12728 we extract the feature previously known as \"disabled autoFlush\" into a separate interface called {{BufferedMutator}}. This interface is like {{Table}} only exposes mutation operations. It would be useful to provide an adapter that wraps up a {{BufferedMutator}} instance, providing the rest of the {{Table}} interface API. That way, it's easier for existing code to \"drop-in\" the new API."
    ],
    [
        "HBASE-6620",
        "HBASE-5725",
        "Test org.apache.hadoop.hbase.client.TestFromClientSideWithCoprocessor.testPoolBehavior flaps in autobuilds. Test flaps in autobuilds with assertion failure.\r\n\r\n\r\norg.apache.hadoop.hbase.client.TestFromClientSideWithCoprocessor.testPoolBehavior\r\n\r\nFailing for the past 1 build (Since #2602 )\r\nTook 3 ms.\r\nError Message\r\n\r\nexpected:<3> but was:<4>\r\nStacktrace\r\n\r\njava.lang.AssertionError: expected:<3> but was:<4>\r\n\tat org.junit.Assert.fail(Assert.java:93)\r\n\tat org.junit.Assert.failNotEquals(Assert.java:647)\r\n\tat org.junit.Assert.assertEquals(Assert.java:128)\r\n\tat org.junit.Assert.assertEquals(Assert.java:472)\r\n\tat org.junit.Assert.assertEquals(Assert.java:456)\r\n\tat org.apache.hadoop.hbase.client.TestFromClientSide.testPoolBehavior(TestFromClientSide.java:4334)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\r\n\tat java.lang.reflect.Method.invoke(Method.java:597)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\r\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\r\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\r\n\tat org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:47)\r\n\tat org.junit.rules.RunRules.evaluate(RunRules.java:18)\r\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\r\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\r\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\r\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\r\n\tat org.junit.runners.Suite.runChild(Suite.java:128)\r\n\tat org.junit.runners.Suite.runChild(Suite.java:24)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)\r\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\r\n\tat java.lang.Thread.run(Thread.java:662)\r\n",
        "HBaseClient throws NPE while in Connection#receiveResponse call. When i am running TestSplitTransactionOnCluster, it is throwing NPE from HBaseClient \r\n\r\nHBaseClient:\r\n \r\nRpcResponse response = RpcResponse.parseDelimitedFrom(in);\r\n int id = response.getCallId();\r\n\r\nThe above code throws NPE.\r\n"
    ]
]